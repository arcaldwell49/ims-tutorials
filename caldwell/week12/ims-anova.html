<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />
<meta name="learnr-version-prerender" content="0.11.5" />

<title>Week 12: Comparing many means with ANOVA</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->


</head>

<body>
<a class='sr-only sr-only-focusable visually-hidden-focusable' href='#learnr-tutorial-content'>Skip to Tutorial Content</a>



<div class="pageContent band">
<main class="bandContent page">

<article class="topics" id="learnr-tutorial-content">

<div id="section-welcome" class="section level2">
<h2>Welcome</h2>
<div id="section-introduction" class="section level3">
<h3>Introduction</h3>
<p>Welcome to this interactive tutorial on Analysis of Variance (ANOVA)!
In this tutorial, you’ll learn how to compare means across multiple
groups simultaneously—a powerful extension of the two-sample t-test
you’ve learned previously.</p>
<p>We’ll work with real data from the General Social Survey to
investigate an interesting question: Is there a relationship between
vocabulary scores and self-identified social class?</p>
<p>Throughout this tutorial, you’ll not only learn the mechanics of
ANOVA but also understand <em>why</em> we need this method and how to
properly interpret and communicate results.</p>
</div>
<div id="section-learning-objectives" class="section level3">
<h3>Learning Objectives</h3>
<p>By the end of this tutorial, you will be able to:</p>
<ol style="list-style-type: decimal">
<li><strong>Conduct exploratory data analysis</strong> for comparing a
numerical variable across multiple groups using appropriate
visualizations</li>
<li><strong>State hypotheses</strong> for an ANOVA test in both words
and mathematical notation</li>
<li><strong>Check conditions</strong> for ANOVA, including independence,
normality, and equal variance</li>
<li><strong>Perform an ANOVA</strong> to test whether means differ
across groups and interpret the F-statistic</li>
<li><strong>Interpret ANOVA results</strong>, including understanding
degrees of freedom, sum of squares, and p-values</li>
<li><strong>Explain the multiple comparisons problem</strong> and why
adjustments are necessary when conducting pairwise tests</li>
<li><strong>Conduct post-hoc pairwise comparisons</strong> using modern
methods including Bonferroni, Holm, FDR (False Discovery Rate), and
Tukey HSD adjustments</li>
<li><strong>Use the <code>emmeans</code> package</strong> for estimating
and comparing marginal means in a principled way</li>
</ol>
</div>
</div>
<div id="section-introduction-to-the-data" class="section level2">
<h2>Introduction to the Data</h2>
<div id="section-research-question" class="section level3">
<h3>Research Question</h3>
<p><strong>Does vocabulary score vary by social class?</strong></p>
<p>This is an example of a question where we need to compare means
across <strong>more than two</strong> groups. A t-test won’t work here
because:</p>
<ul>
<li>A t-test can only compare <strong>two</strong> groups at a time</li>
<li>Doing multiple t-tests (lower vs. working, lower vs. middle, etc.)
creates statistical problems we’ll discuss later</li>
<li>We need a method that can test all groups
<strong>simultaneously</strong></li>
</ul>
<p>Enter ANOVA: <strong>AN</strong>alysis <strong>O</strong>f
<strong>VA</strong>riance.</p>
</div>
<div id="section-the-dataset-general-social-survey"
class="section level3">
<h3>The Dataset: General Social Survey</h3>
<p>Our data comes from the <strong>General Social Survey (GSS)</strong>,
a nationally representative survey of adults in the United States
conducted since 1972. The GSS tracks social trends and attitudes over
time.</p>
<p>For this analysis, we’ll focus on two variables:</p>
<blockquote>
<ul>
<li><code>wordsum</code>: Score on a 10-question vocabulary test (scores
range from 0 to 10)</li>
<li><code>class</code>: Self-identified social class with 4 levels
(lower, working, middle, upper)</li>
</ul>
</blockquote>
<p>Here’s a glimpse of our data:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left"><code>wordsum</code></th>
<th align="left"><code>class</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">6</td>
<td align="left">MIDDLE</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">9</td>
<td align="left">WORKING</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">6</td>
<td align="left">WORKING</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">5</td>
<td align="left">WORKING</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">WORKING</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">6</td>
<td align="left">WORKING</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
</tr>
<tr class="even">
<td align="left">795</td>
<td align="left">9</td>
<td align="left">MIDDLE</td>
</tr>
</tbody>
</table>
<p>We have 795 respondents who answered both the vocabulary questions
and the social class question.</p>
</div>
<div id="section-the-vocabulary-test-wordsum" class="section level3">
<h3>The Vocabulary Test: <code>wordsum</code></h3>
<p>Respondents are given a list of words and asked to choose which word
comes closest to the meaning of a word provided in capital letters. Here
are the 10 questions:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>SPACE (school, noon, captain, room, board, don’t know)</li>
<li>BROADEN (efface, make level, elapse, embroider, widen, don’t
know)</li>
<li>EMANATE (populate, free, prominent, rival, come, don’t know)</li>
<li>EDIBLE (auspicious, eligible, fit to eat, sagacious, able to speak,
don’t know)</li>
<li>ANIMOSITY (hatred, animation, disobedience, diversity, friendship,
don’t know)</li>
<li>PACT (puissance, remonstrance, agreement, skillet, pressure, don’t
know)</li>
<li><strong>CLOISTERED (miniature, bunched, arched, malady, secluded,
don’t know)</strong></li>
<li>CAPRICE (value, a star, grimace, whim, inducement, don’t know)</li>
<li>ACCUSTOM (disappoint, customary, encounter, get used to, business,
don’t know)</li>
<li>ALLUSION (reference, dream, eulogy, illusion, aria, don’t know)</li>
</ol>
</blockquote>
<p><strong>Try one!</strong> For example, is CLOISTERED closest in
meaning to miniature, bunched, arched, malady, or secluded?</p>
<p>(The correct answer is <strong>secluded</strong>—cloistered means
isolated or shut away from the world, often in a religious context.)</p>
<p><strong>Why vocabulary scores?</strong> Vocabulary tests are commonly
used as proxy measures for educational attainment and verbal cognitive
ability. The GSS uses this 10-word test to measure respondents’ verbal
skills in a quick, standardized way.</p>
</div>
<div id="section-distribution-of-vocabulary-score"
class="section level3">
<h3>Distribution of Vocabulary Score</h3>
<p>Let’s start by looking at the overall distribution of vocabulary
scores, ignoring social class for now:</p>
<pre class="r"><code>ggplot(data = gss, aes(x = wordsum)) +
  geom_histogram(binwidth = 1)</code></pre>
<p><img src="ims-anova_files/figure-html/unnamed-chunk-1-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>The distribution of vocabulary scores is roughly symmetric and
centered around 6. Scores range from 0 to 10, though very low and very
high scores are uncommon. There’s a slight left skew, but nothing
dramatic. Most people score between 4 and 8 on this test.</p>
</div>
<div id="section-self-identified-social-class-class"
class="section level3">
<h3>Self-Identified Social Class: <code>class</code></h3>
<p>Respondents were asked:</p>
<p><em>“If you were asked to use one of four names for your social
class, which would you say you belong in: the lower class, the working
class, the middle class, or the upper class?”</em></p>
<p>Let’s see how many people selected each category:</p>
<pre class="r"><code>ggplot(data = gss, aes(x = class)) +
  geom_bar()</code></pre>
<p><img src="ims-anova_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>The majority of respondents identify as working class or middle
class. Relatively few identify as lower or upper class. This
distribution reflects common patterns in American
self-identification—most people place themselves in the “middle”
categories.</p>
</div>
<div id="section-making-the-connection" class="section level3">
<h3>Making the Connection</h3>
<p>These visualizations tell us about each variable individually, but
they don’t reveal whether there’s a <strong>relationship</strong>
between them.</p>
<p><strong>The key question:</strong> Do vocabulary scores differ
systematically across social class groups? Or is any variation we see
just random noise?</p>
<p>To answer this, we need to:</p>
<ol style="list-style-type: decimal">
<li>Visualize the relationship (next section!)</li>
<li>Formalize our question as statistical hypotheses</li>
<li>Check whether our data meet the conditions for ANOVA</li>
<li>Conduct the analysis and interpret results</li>
</ol>
<p>Time to dig in!</p>
</div>
</div>
<div id="section-exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<div id="section-eda-a-critical-first-step" class="section level3">
<h3>EDA: A Critical First Step</h3>
<p>Before jumping into any statistical test, we should <strong>always
visualize the data first</strong>. Visualization helps us:</p>
<ul>
<li>Understand the relationship between variables</li>
<li>Check whether ANOVA assumptions might be reasonably met</li>
<li>Develop intuition about what the statistical analysis might
reveal</li>
<li>Identify potential outliers or unusual patterns</li>
</ul>
<p><strong>Remember:</strong> Statistical tests give us precise
p-values, but visualizations give us understanding. Both are
essential!</p>
</div>
<div id="section-your-task-visualizing-the-relationship"
class="section level3">
<h3>Your Task: Visualizing the Relationship</h3>
<p>Now it’s your turn to explore the data!</p>
<p>Create visualizations to compare vocabulary scores across social
class groups.</p>
<p><strong>Your task:</strong></p>
<ul>
<li>Using the <code>gss</code> dataset, create a histogram of vocabulary
scores (<code>wordsum</code>)</li>
<li>Use an appropriate binwidth (remember: scores are whole numbers from
0-10)</li>
<li>Facet the histogram by social class level (<code>class</code>)</li>
</ul>
<p><strong>After creating the plot, carefully compare the
distributions.</strong> Look at:</p>
<ul>
<li><strong>Shape:</strong> Are the distributions roughly symmetric?
Skewed?</li>
<li><strong>Center:</strong> Do the groups appear to have different
average scores?</li>
<li><strong>Spread:</strong> Is the variability similar across
groups?</li>
<li><strong>Unusual observations:</strong> Are there outliers in any
group?</li>
</ul>
<div class="tutorial-exercise" data-label="vocabulary"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Using gss, plot wordsum
ggplot(data = ___, mapping = aes(___)) +
  # Add a histogram layer with appropriate binwidth
  ___ +
  # Facet by class
  facet_wrap(~___)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="vocabulary-hint"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Hints:
# - Use `gss` as the plot&#39;s `data` argument
# - Map `x` to `wordsum` in `aes()`
# - Add a histogram layer with `geom_histogram()`
# - Vocabulary scores are whole numbers, so binwidth = 1 makes sense
# - The faceting formula is specified as `~class`</code></pre>
</div>
<div class="tutorial-exercise-support" data-label="vocabulary-solution"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Using gss, plot wordsum
ggplot(data = gss, mapping = aes(x = wordsum)) +
  # Add a histogram layer
  geom_histogram(binwidth = 1) +
  # Facet by class
  facet_wrap(~class)</code></pre>
</div>
</div>
<div id="section-what-do-you-notice" class="section level3">
<h3>What Do You Notice?</h3>
<p>Great work! Before you move on, take a moment to carefully examine
all aspects of these distributions:</p>
<p><strong>Questions to consider:</strong></p>
<ul>
<li>Do the distributions look roughly similar in shape across
groups?</li>
<li>Which group appears to have the highest average vocabulary
score?</li>
<li>Which group has the lowest?</li>
<li>Is the spread (variability) similar across all four groups?</li>
<li>Are there any obvious outliers?</li>
</ul>
<p>These observations will be important when we check conditions for
ANOVA and interpret our results!</p>
</div>
<div id="section-comparing-many-means-visually" class="section level3">
<h3>Comparing Many Means, Visually</h3>
<p>Let’s develop your intuition about when groups are likely to be
“significantly different” from each other.</p>
<p>Look at the three panels below, each showing boxplots for three
groups:</p>
<p><img src="ims-anova_files/figure-html/means-setup-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="panel panel-default tutorial-question-container">
<div data-label="quiz_1" class="tutorial-question panel-body">
<div id="quiz_1-answer_container" class="shiny-html-output"></div>
<div id="quiz_1-message_container" class="shiny-html-output"></div>
<div id="quiz_1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p><strong>Key insight:</strong> Statistical significance depends on
<strong>both</strong> the difference between group means
<strong>and</strong> the variability within groups. Large differences
with small variability → likely significant. Small differences with
large variability → likely not significant.</p>
</div>
</div>
<div id="section-anova-the-big-picture" class="section level2">
<h2>ANOVA: The Big Picture</h2>
<div id="section-why-not-just-do-multiple-t-tests"
class="section level3">
<h3>Why Not Just Do Multiple t-tests?</h3>
<p>You might be wondering: We know how to compare two means with a
t-test. Why can’t we just do several t-tests for every pair of social
classes?</p>
<p><strong>The problem:</strong> Multiple testing inflates the Type I
error rate dramatically.</p>
<p>Let’s break this down:</p>
<ul>
<li>When we set α = 0.05, we’re accepting a 5% chance of a false
positive (Type I error) for <strong>one</strong> test</li>
<li>With 4 social classes, we’d need to do <span
class="math inline">\({4 \choose 2} = \frac{4 \times 3}{2} = 6\)</span>
pairwise comparisons</li>
<li>The probability of making <strong>at least one</strong> Type I error
across all tests grows rapidly</li>
</ul>
<p><strong>The math:</strong></p>
<p>If we conduct <span class="math inline">\(k\)</span> independent
tests, each at significance level α:</p>
<p><span class="math display">\[P(\text{at least one Type I error}) = 1
- (1-\alpha)^k\]</span></p>
<p>For 6 tests at α = 0.05: <span class="math display">\[P(\text{at
least one Type I error}) = 1 - (0.95)^6 \approx 0.265\]</span></p>
<p>That’s a 26.5% chance of falsely detecting a difference that doesn’t
exist! This is called the <strong>multiple comparisons problem</strong>
or <strong>multiple testing problem</strong>.</p>
<p><strong>The solution:</strong> Use ANOVA to test all groups
simultaneously with a <strong>single test</strong> that controls the
overall Type I error rate at α.</p>
</div>
<div id="section-how-anova-works" class="section level3">
<h3>How ANOVA Works</h3>
<p>ANOVA addresses this problem by comparing <strong>two sources of
variation</strong> in a single F-test:</p>
<ol style="list-style-type: decimal">
<li><strong>Between-group variation:</strong> How much do the group
means differ from each other?</li>
<li><strong>Within-group variation:</strong> How much do individual
observations vary within each group?</li>
</ol>
<p><strong>The logic:</strong></p>
<ul>
<li>If group membership matters (i.e., vocabulary really does differ by
class), we expect <strong>large between-group variation</strong>
relative to within-group variation</li>
<li>If group membership doesn’t matter, between-group variation should
be similar to within-group variation (just random noise)</li>
</ul>
<p><strong>The test statistic is called an F-statistic:</strong></p>
<p><span class="math display">\[F = \frac{\text{Between-group
variability}}{\text{Within-group variability}} =
\frac{\text{MSG}}{\text{MSE}}\]</span></p>
<p>Where: - MSG = Mean Square for Groups (between-group variance) - MSE
= Mean Square Error (within-group variance)</p>
<p><strong>Interpreting F:</strong></p>
<ul>
<li><strong>Large F-values</strong> (much greater than 1) suggest group
means are different</li>
<li><strong>F-values near 1</strong> suggest group means are similar
(differences are just noise)</li>
<li>F-values are always positive (it’s a ratio of variances)</li>
</ul>
<p>The F-distribution helps us determine whether an observed F-value is
“unusually large” if the null hypothesis were true.</p>
</div>
<div id="section-variability-partitioning" class="section level3">
<h3>Variability Partitioning</h3>
<p>ANOVA works by <strong>partitioning</strong> (dividing up) the total
variability in the response variable:</p>
<p><span class="math display">\[\text{Total Variability} =
\text{Between-group Variability} + \text{Within-group
Variability}\]</span></p>
<p>For our vocabulary score example:</p>
<p><strong>Total variability</strong> in vocabulary scores = variance in
vocabulary scores of all 795 respondents</p>
<p><strong>Between-group variability</strong> = variability that can be
attributed to differences in social class. This is what we’re interested
in! If social class matters, this component should be large.</p>
<p><strong>Within-group variability</strong> = variability attributed to
factors within each social group. This is essentially “noise”—if
everyone in a social class had exactly the same vocabulary score, this
would be zero (but that never happens in real data!).</p>
<p><strong>The key insight:</strong> We want between-group variability
to be large <strong>relative to</strong> within-group variability. The
F-statistic makes this comparison.</p>
<blockquote>
<p><strong>Summary of key concepts:</strong></p>
<ul>
<li>Total variability is partitioned into two components:
<ul>
<li><strong>Between-group variability:</strong> differences attributable
to the grouping variable</li>
<li><strong>Within-group variability:</strong> differences within each
group (the “noise”)</li>
</ul></li>
<li>ANOVA uses a single F-test to compare all groups simultaneously</li>
<li>This controls the Type I error rate (unlike doing multiple
t-tests)</li>
<li>Large F-statistics suggest the group means differ</li>
</ul>
</blockquote>
<p>Next, we’ll formalize this with hypotheses and see what an actual
ANOVA looks like!</p>
</div>
</div>
<div id="section-hypotheses-and-the-anova-table" class="section level2">
<h2>Hypotheses and the ANOVA Table</h2>
<div
id="section-anova-hypotheses-for-vocabulary-scores-vs.-social-class"
class="section level3">
<h3>ANOVA Hypotheses for Vocabulary Scores vs. Social Class</h3>
<p>Every ANOVA starts with a pair of hypotheses. Let’s state them
clearly:</p>
<p><strong>Null hypothesis (H₀):</strong> The average vocabulary score
is the same across all social classes</p>
<p><span class="math display">\[H_0: \mu_{\text{lower}} =
\mu_{\text{working}} = \mu_{\text{middle}} =
\mu_{\text{upper}}\]</span></p>
<p><strong>Alternative hypothesis (Hₐ):</strong> The average vocabulary
score for <strong>at least one</strong> social class differs from the
others</p>
<p><strong>Critical point:</strong> The alternative hypothesis is
<strong>NOT</strong> that all the groups are different from each other!
It only says that <strong>at least one</strong> group mean is
different.</p>
<p>Think about it this way:</p>
<ul>
<li>✓ Lower ≠ Upper (but all others equal) → Alternative hypothesis is
true</li>
<li>✓ Lower ≠ Working ≠ Middle (but Upper = Middle) → Alternative
hypothesis is true<br />
</li>
<li>✓ All four are different → Alternative hypothesis is true</li>
<li>✗ All four are equal → Null hypothesis is true</li>
</ul>
<p><strong>Why “at least one”?</strong> The negation (opposite) of “all
groups are equal” is “at least one group is different.” This is why we
need post-hoc tests after ANOVA—to figure out <strong>which</strong>
groups differ!</p>
</div>
<div id="section-the-anova-table" class="section level3">
<h3>The ANOVA Table</h3>
<p>Here’s what the parametric (theoretical) ANOVA output looks like for
our vocabulary data:</p>
<pre class="r"><code>aov(wordsum ~ class, gss) |&gt;
  tidy()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["df"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sumsq"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["meansq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"class","2":"3","3":"236.5644","4":"78.854810","5":"21.73467","6":"1.560565e-13"},{"1":"Residuals","2":"791","3":"2869.8003","4":"3.628066","5":"NA","6":"NA"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Let’s break down each component of this output:</p>
<p><strong>Row 1 (class):</strong> The “between-group”
variability—variation explained by social class</p>
<p><strong>Row 2 (Residuals):</strong> The “within-group”
variability—unexplained variation (the “error”)</p>
<p>Now let’s examine each column:</p>
</div>
<div id="section-understanding-sum-of-squares" class="section level3">
<h3>Understanding Sum of Squares</h3>
<p>The <strong>Sum of Squares (sumsq)</strong> column measures
variability:</p>
<ul>
<li><strong>SS for class (236.56):</strong> Variability in vocabulary
scores explained by social class</li>
<li><strong>SS for Residuals (2869.80):</strong> Unexplained variability
(variation within groups)</li>
<li><strong>Total SS = 236.56 + 2869.80 = 3106.36:</strong> Total
variability in vocabulary scores</li>
</ul>
<p><strong>Sum of Squares Total (SST)</strong> is calculated as the
total squared deviation from the overall mean:</p>
<p><span class="math display">\[SST = \sum_{i=1}^{n}(y_i -
\bar{y})^2\]</span></p>
<p>This is similar to variance, but not divided by n.</p>
<p><strong>Percentage of variability explained:</strong></p>
<p><span class="math display">\[R^2 =
\frac{SS_{\text{class}}}{SS_{\text{total}}} = \frac{236.56}{3106.36} =
0.076 = 7.6\%\]</span></p>
<p><strong>Interpretation:</strong> About 7.6% of the variability in
vocabulary scores can be explained by self-identified social class. The
remaining 92.4% is due to other factors (education, age, reading habits,
etc.).</p>
<p><strong>Note:</strong> This R² is exactly what you’d get from a
linear regression predicting wordsum from class!</p>
</div>
<div id="section-degrees-of-freedom-df" class="section level3">
<h3>Degrees of Freedom (df)</h3>
<p><strong>df for class:</strong> Number of groups - 1 = 4 - 1 =
<strong>3</strong></p>
<p><strong>df for Residuals:</strong> Total observations - number of
groups = 795 - 4 = <strong>791</strong></p>
<p>Degrees of freedom tell us how many “independent pieces of
information” we have for estimating variability.</p>
</div>
<div id="section-mean-square-meansq" class="section level3">
<h3>Mean Square (meansq)</h3>
<p>Mean Square values are the Sum of Squares divided by degrees of
freedom:</p>
<p><span class="math display">\[MS = \frac{SS}{df}\]</span></p>
<ul>
<li><strong>MSG (Mean Square Groups) = 236.56 / 3 = 78.85:</strong>
Average between-group variability</li>
<li><strong>MSE (Mean Square Error) = 2869.80 / 791 = 3.63:</strong>
Average within-group variability</li>
</ul>
<p>These are variance estimates! Mean squares are how we standardize the
variability measures for groups with different degrees of freedom.</p>
</div>
<div id="section-the-f-statistic" class="section level3">
<h3>The F-Statistic</h3>
<p>The F-statistic is the ratio of between-group to within-group
variability:</p>
<p><span class="math display">\[F = \frac{MSG}{MSE} = \frac{78.85}{3.63}
= 21.74\]</span></p>
<p><strong>Interpretation:</strong> The between-group variability is
about 21.74 times larger than the within-group variability. This is a
large ratio!</p>
</div>
<div id="section-the-p-value" class="section level3">
<h3>The p-value</h3>
<p>The <strong>p-value (&lt; 0.001)</strong> answers this question:</p>
<p><em>“If the null hypothesis were true (all group means equal), what’s
the probability of observing an F-statistic this large or
larger?”</em></p>
<p>Here, p &lt; 0.001 means: extremely unlikely!</p>
<p><strong>Decision:</strong> Since p-value &lt; α (typically 0.05), we
<strong>reject the null hypothesis</strong>.</p>
<p><strong>Conclusion:</strong> We have very strong evidence that
average vocabulary scores differ across at least one pair of social
class groups.</p>
<p><strong>But…</strong> we still don’t know <strong>which</strong>
groups differ! That’s where post-hoc testing comes in (we’ll get there
soon).</p>
</div>
<div id="section-the-f-distribution" class="section level3">
<h3>The F-Distribution</h3>
<p>ANOVA uses the F-distribution to calculate p-values. Here’s what the
F-distribution looks like for our analysis:</p>
<pre class="r"><code>obs_stat &lt;- aov(wordsum ~ class, gss) |&gt; 
  tidy() |&gt; 
  select(statistic) |&gt; 
  slice(1) |&gt; 
  pull()

set.seed(1234)

values &lt;- tibble(
  val = rf(100000, df1 = 3, df2 = 791)
)

values |&gt; 
ggplot(aes(x = val)) + 
  geom_density() + 
  xlim(c(0, 25)) + 
  labs(x = &quot;F-statistic&quot;, 
       y = &quot;Density&quot;, 
       title = &quot;F-distribution with df1 = 3, df2 = 791&quot;) + 
  geom_vline(xintercept = obs_stat, color = &quot;red&quot;, linetype = &quot;dashed&quot;) +
  annotate(&quot;text&quot;, x = obs_stat + 2, y = 0.4, 
           label = paste(&quot;Observed F =&quot;, round(obs_stat, 2)), 
           color = &quot;red&quot;)</code></pre>
<p><img src="ims-anova_files/figure-html/unnamed-chunk-4-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><strong>Key features of the F-distribution:</strong></p>
<ul>
<li>Always positive (it’s a ratio of two variances)</li>
<li>Right-skewed</li>
<li>Defined by two degrees of freedom parameters (df₁ and df₂)</li>
<li>For ANOVA, we <strong>only</strong> use the upper (right) tail to
calculate p-values</li>
</ul>
<p>The red dashed line shows our observed F-statistic (21.74). It’s way
out in the right tail—extremely unlikely if H₀ were true!</p>
</div>
</div>
<div id="section-conducting-your-own-anova" class="section level2">
<h2>Conducting Your Own ANOVA</h2>
<p>Time to put this into practice!</p>
<div id="section-anova-for-evaluation-score-vs.-professor-rank"
class="section level3">
<h3>ANOVA for Evaluation Score vs. Professor Rank</h3>
<p>Let’s conduct an ANOVA using different data. The <code>evals</code>
dataset contains course evaluation scores for professors at the
University of Texas at Austin, along with various characteristics
including their academic rank.</p>
<p><strong>Research question:</strong> Is there a difference in average
evaluation scores between professors of different ranks?</p>
<p>The <code>rank</code> variable has three levels: - teaching: Teaching
faculty - tenure track: Tenure-track faculty (assistant/associate
professors) - tenured: Tenured (full) professors</p>
<p><strong>Your task:</strong></p>
<ul>
<li>Use the <code>aov()</code> function to perform an ANOVA testing
whether evaluation <code>score</code> differs by professor
<code>rank</code></li>
<li>Store the result as <code>aov_evals_rank</code></li>
<li>Use <code>tidy()</code> to view a clean summary of the ANOVA
table</li>
<li>Interpret the results at α = 0.025 (2.5% significance level)</li>
</ul>
<div class="tutorial-exercise" data-label="vocabulary_2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Run an analysis of variance on score vs. rank
aov_evals_rank &lt;- aov(___, data = ___)

# Tidy the model
tidy(___)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="vocabulary_2-hint"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Hints:
# - Call `aov()` with a formula: response ~ grouping_variable
# - The formula should be: score ~ rank
# - Use the `evals` dataset
# - Call `tidy()` on the stored ANOVA object</code></pre>
</div>
<div class="tutorial-exercise-support"
data-label="vocabulary_2-solution" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code># Run an analysis of variance on score vs. rank
aov_evals_rank &lt;- aov(score ~ rank, data = evals)

# Tidy the model
tidy(aov_evals_rank)</code></pre>
</div>
</div>
<div id="section-interpreting-your-results" class="section level3">
<h3>Interpreting Your Results</h3>
<p>Now that you’ve run the ANOVA, answer these questions:</p>
<ol style="list-style-type: decimal">
<li><strong>What is the F-statistic?</strong> Is it large?</li>
<li><strong>What is the p-value?</strong> Is it less than α =
0.025?</li>
<li><strong>What is your decision?</strong> Reject or fail to reject
H₀?</li>
<li><strong>What is your conclusion in context?</strong> Do evaluation
scores appear to differ by professor rank?</li>
</ol>
<p><strong>Bonus question:</strong> Would your conclusion change if you
had used a 10% significance level (α = 0.10) instead?</p>
<p>Take a moment to write out your interpretation before moving on!</p>
</div>
</div>
<div id="section-conditions-for-anova" class="section level2">
<h2>Conditions for ANOVA</h2>
<div id="section-why-conditions-matter" class="section level3">
<h3>Why Conditions Matter</h3>
<p>Just like any statistical inference method, ANOVA has mathematical
conditions that must be reasonably satisfied for the results to be
trustworthy.</p>
<p><strong>Important note:</strong> We can never mathematically “prove”
conditions are perfectly met with real data. Instead, we use careful
evaluation to assess whether conditions are reasonably satisfied or
seriously violated.</p>
</div>
<div id="section-three-main-conditions-for-anova"
class="section level3">
<h3>Three Main Conditions for ANOVA</h3>
<ol style="list-style-type: decimal">
<li><strong>Independence:</strong>
<ul>
<li>Within groups: sampled observations must be independent of each
other</li>
<li>Between groups: the groups themselves must be independent</li>
</ul></li>
<li><strong>Approximate normality:</strong>
<ul>
<li>The response variable should be approximately normal <strong>within
each group</strong></li>
</ul></li>
<li><strong>Equal variance (homoscedasticity):</strong>
<ul>
<li>The variability should be roughly equal across all groups</li>
</ul></li>
</ol>
<p>Let’s examine each condition in detail and learn how to check
them.</p>
</div>
<div id="section-condition-1-independence" class="section level3">
<h3>Condition 1: Independence</h3>
<p><strong>Within groups:</strong> Sampled observations must be
independent of each other</p>
<p>How to verify: - ✓ <strong>Random sampling</strong> ensures
independence - ✓ For experiments: random assignment helps (but consider
potential relationships) - ✓ <strong>10% rule:</strong> Each sample size
should be less than 10% of its respective population - ✓ No obvious
clustering or time dependencies</p>
<p><strong>Between groups:</strong> Groups must be independent of each
other</p>
<p>What to watch for: - ✗ <strong>Paired or repeated measures:</strong>
Same subjects measured in multiple groups - ✗ <strong>Matched
samples:</strong> Groups deliberately matched on characteristics - ✓
<strong>Different subjects</strong> in each group</p>
<p><strong>For our GSS vocabulary data:</strong></p>
<ul>
<li>✓ The GSS uses random sampling → within-group independence
satisfied</li>
<li>✓ Sample size (n = 795) is much less than 10% of the US adult
population</li>
<li>✓ Each respondent appears in only one social class group →
between-group independence satisfied</li>
</ul>
<p><strong>Important:</strong> This condition is <strong>always
critical</strong> but sometimes difficult to verify without knowing the
study design details.</p>
</div>
<div id="section-condition-2-approximate-normality"
class="section level3">
<h3>Condition 2: Approximate Normality</h3>
<p><strong>Requirement:</strong> The response variable should be
approximately normal <strong>within each group</strong></p>
<p><strong>When it matters most:</strong> When sample sizes are
<strong>small</strong> (n &lt; 30 per group)</p>
<p><strong>When it matters less:</strong> When sample sizes are
<strong>large</strong>, ANOVA is fairly robust to violations of
normality (thanks to the Central Limit Theorem)</p>
<p><strong>How to check:</strong></p>
<ul>
<li>Create visualizations <strong>for each group separately:</strong>
<ul>
<li>Histograms or density plots (check for symmetry, outliers)</li>
<li>Q-Q plots (points should fall roughly on a straight line)</li>
<li>Violin plots (show full distribution shape)</li>
</ul></li>
<li>Look for:
<ul>
<li>✓ Roughly symmetric distributions</li>
<li>✓ No extreme outliers</li>
<li>⚠ Moderate skewness is usually okay with large samples</li>
<li>✗ Severe skewness or heavy outliers in small samples</li>
</ul></li>
</ul>
<p><strong>Which visualization is best for checking
normality?</strong></p>
<div class="panel panel-default tutorial-question-container">
<div data-label="quiz_2" class="tutorial-question panel-body">
<div id="quiz_2-answer_container" class="shiny-html-output"></div>
<div id="quiz_2-message_container" class="shiny-html-output"></div>
<div id="quiz_2-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
</div>
<div id="section-condition-3-constant-equal-variance"
class="section level3">
<h3>Condition 3: Constant (Equal) Variance</h3>
<p><strong>Requirement:</strong> The variability of the response
variable should be roughly equal across all groups</p>
<p><strong>Technical term:</strong> Homoscedasticity (homo = same,
scedastic = scatter)</p>
<p><strong>When it matters most:</strong> When sample sizes
<strong>differ substantially</strong> between groups</p>
<p><strong>When it matters less:</strong> When sample sizes are
<strong>balanced</strong> (roughly equal), ANOVA is fairly robust</p>
<p><strong>How to check:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Visual inspection:</strong>
<ul>
<li>Boxplots: Check if box heights and whisker lengths are similar</li>
<li>Violin plots: Check if widths are similar</li>
<li>Residual plots: Points should be equally scattered at all fitted
values</li>
</ul></li>
<li><strong>Numerical summary:</strong>
<ul>
<li>Calculate standard deviations for each group</li>
<li><strong>Rule of thumb:</strong> Largest SD should be no more than 2×
the smallest SD</li>
<li>If max(SD) / min(SD) &gt; 2, equal variance might be violated</li>
</ul></li>
</ol>
<p>Let’s check this condition for our vocabulary data!</p>
</div>
<div id="section-checking-equal-variance-numerical-approach"
class="section level3">
<h3>Checking Equal Variance: Numerical Approach</h3>
<p>Calculate the standard deviation of vocabulary scores within each
social class group.</p>
<p><strong>Your task:</strong></p>
<ol style="list-style-type: decimal">
<li>Take the <code>gss</code> dataset and <code>group_by()</code> social
<code>class</code></li>
<li>Use <code>summarize()</code> to calculate the standard deviation
(<code>sd()</code>) of <code>wordsum</code></li>
<li>Store the result in a column called <code>sd_wordsum</code></li>
<li>Examine the results: Is the ratio of largest to smallest SD less
than 2?</li>
</ol>
<div class="tutorial-exercise" data-label="vocabulary_3"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code>gss |&gt;
  # Group by class
  group_by(___) |&gt;
  # Calculate the std dev of wordsum as sd_wordsum
  summarize(___ = ___)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="vocabulary_3-hint"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Hints:
# - Call `group_by()`, passing `class` as the argument
# - In `summarize()`, create `sd_wordsum` by calling `sd(wordsum)`
# - After running, look at the SD values: 
#   Is the largest about 2x the smallest or more?</code></pre>
</div>
<div class="tutorial-exercise-support"
data-label="vocabulary_3-solution" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code>gss |&gt;
  # Group by class
  group_by(class) |&gt;
  # Calculate the std dev of wordsum as sd_wordsum
  summarize(sd_wordsum = sd(wordsum))</code></pre>
</div>
</div>
<div id="section-checking-equal-variance-visual-approach"
class="section level3">
<h3>Checking Equal Variance: Visual Approach</h3>
<p>Standard deviations give us numbers, but visualizations help us
<strong>see</strong> the variability.</p>
<p><strong>Your task:</strong> Create density ridge plots to visualize
the distribution of vocabulary scores across social classes.</p>
<p><strong>Steps:</strong></p>
<ol style="list-style-type: decimal">
<li>Pipe the <code>gss</code> dataset into <code>ggplot()</code></li>
<li>Map <code>wordsum</code> to the x-axis and <code>class</code> to the
y-axis in <code>aes()</code></li>
<li>Add density ridges using <code>geom_density_ridges()</code></li>
<li>Examine the plot: Do the distributions have similar spread?</li>
</ol>
<div class="tutorial-exercise" data-label="vocabulary_4"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code>gss |&gt;
  # Map wordsum to the x-axis and class to the y-axis
  ggplot(aes(x = ___, y = ___)) +
  # Add density ridges to the plot! 
  geom_density_ridges()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="vocabulary_4-hint"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Hints:
# - Map x = wordsum (the response variable)
# - Map y = class (the grouping variable)
# - geom_density_ridges() is already provided!
# - Look at the widths of the density curves</code></pre>
</div>
<div class="tutorial-exercise-support"
data-label="vocabulary_4-solution" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code>gss |&gt;
  # Map wordsum to the x-axis and class to the y-axis
  ggplot(aes(x = wordsum, y = class)) +
  # Add density ridges to the plot! 
  geom_density_ridges()</code></pre>
</div>
</div>
<div id="section-reflection-is-equal-variance-satisfied"
class="section level3">
<h3>Reflection: Is Equal Variance Satisfied?</h3>
<p>Look at both your numerical summaries and the density ridges
plot.</p>
<p><strong>Questions to consider:</strong></p>
<ul>
<li>Do the standard deviations differ by more than a factor of 2?</li>
<li>Do the density curves have visibly different widths?</li>
<li>If there are some differences, are they minor or substantial?</li>
</ul>
<p><strong>For our data:</strong> The standard deviations are pretty
similar across groups (ranging roughly from 1.8 to 2.0), and the density
curves show comparable spread. The equal variance condition appears
reasonably satisfied!</p>
</div>
<div id="section-checking-conditions-model-based-approach"
class="section level3">
<h3>Checking Conditions: Model-Based Approach</h3>
<p>We can also check normality and equal variance using <strong>residual
plots</strong> from the fitted model, similar to what we did for linear
regression.</p>
<p>The <code>ggfortify</code> package makes this easy with the
<code>autoplot()</code> function:</p>
<pre class="r"><code>autoplot(lm(wordsum ~ factor(class), gss), which = 2:3)</code></pre>
<p><img src="ims-anova_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><strong>Left plot (Q-Q plot):</strong> Checks normality of
residuals</p>
<ul>
<li>Points should fall roughly along the diagonal line</li>
<li>Our data: Mostly linear with slight deviations at the
tails—normality is reasonably satisfied</li>
</ul>
<p><strong>Right plot (Scale-Location):</strong> Checks equal
variance</p>
<ul>
<li>The red smoothed line should be roughly horizontal</li>
<li>Points should be evenly scattered above and below</li>
<li>Our data: The line is fairly flat—equal variance assumption is
reasonable</li>
</ul>
<p><strong>Overall assessment for the vocabulary ANOVA:</strong></p>
<ul>
<li>✓ Independence: Satisfied (random sampling, large population)</li>
<li>✓ Normality: Reasonably satisfied (Q-Q plot looks good, large sample
sizes)</li>
<li>✓ Equal variance: Reasonably satisfied (SDs similar, scale-location
plot okay)</li>
</ul>
<p><strong>Conclusion:</strong> We can proceed with confidence in our
ANOVA results!</p>
</div>
</div>
<div id="section-post-hoc-testing-with-emmeans" class="section level2">
<h2>Post-Hoc Testing with emmeans</h2>
<div id="section-the-next-question-which-groups-differ"
class="section level3">
<h3>The Next Question: Which Groups Differ?</h3>
<p>We conducted our ANOVA and found a significant result (p &lt; 0.001).
This tells us that <strong>at least one</strong> social class group has
a different average vocabulary score.</p>
<p><strong>But which ones?</strong></p>
<ul>
<li>Is lower class different from upper class?</li>
<li>Is working class different from middle class?</li>
<li>Are all four groups different from each other?</li>
</ul>
<p>ANOVA doesn’t answer these questions—it only tells us “something
differs somewhere.”</p>
<p>To answer the “which groups?” question, we need <strong>post-hoc
tests</strong> (Latin for “after this”)—tests conducted
<strong>after</strong> finding a significant ANOVA result.</p>
</div>
<div id="section-the-multiple-comparisons-problem-revisited"
class="section level3">
<h3>The Multiple Comparisons Problem: Revisited</h3>
<p>Earlier, we saw why doing multiple t-tests inflates the Type I error
rate. Let’s see this more concretely.</p>
<p><strong>Scenario:</strong> Imagine you’re testing 20 fair coins to
see if they’re biased. For each coin, you set α = 0.05.</p>
<ul>
<li>For each individual coin test: 5% chance of falsely concluding it’s
biased</li>
<li>Across all 20 tests: You’d expect to falsely “detect” bias in about
1 coin purely by chance!</li>
</ul>
<p><span class="math display">\[P(\text{at least one Type I error}) = 1
- (1-\alpha)^k\]</span></p>
<p>For our vocabulary data with <strong>4 groups</strong>, we have <span
class="math inline">\({4 \choose 2} = 6\)</span> possible pairwise
comparisons:</p>
<ol style="list-style-type: decimal">
<li>Lower vs. Working</li>
<li>Lower vs. Middle<br />
</li>
<li>Lower vs. Upper</li>
<li>Working vs. Middle</li>
<li>Working vs. Upper</li>
<li>Middle vs. Upper</li>
</ol>
<p>At α = 0.05 per test: <span class="math display">\[P(\text{at least
one false positive}) = 1 - (0.95)^6 \approx 0.265\]</span></p>
<p>That’s a <strong>26.5% chance</strong> of making at least one Type I
error! Our “5% significance level” is meaningless.</p>
<p><strong>The solution:</strong> Adjust our significance level to
control the <strong>family-wise error rate</strong> (FWER) or
<strong>false discovery rate</strong> (FDR).</p>
</div>
<div id="section-why-use-emmeans" class="section level3">
<h3>Why Use emmeans?</h3>
<p>The <code>emmeans</code> package (<strong>e</strong>stimated
<strong>m</strong>arginal <strong>means</strong>) is a modern,
principled approach to post-hoc testing. Here’s why it’s better than
doing individual t-tests:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Pools information across groups:</strong> Uses the
overall MSE (pooled variance) from the ANOVA model, giving more stable
estimates</p></li>
<li><p><strong>Handles complex designs:</strong> Works seamlessly with
unbalanced designs, covariates, and interactions</p></li>
<li><p><strong>Multiple comparison adjustments:</strong> Easily
implements Bonferroni, Holm, Tukey, FDR, and many other
adjustments</p></li>
<li><p><strong>Consistent framework:</strong> Same syntax works for
ANOVA, regression, mixed models, and more</p></li>
<li><p><strong>Clear output:</strong> Provides confidence intervals and
adjusted p-values in easy-to-read tables</p></li>
</ol>
<p><strong>Key concept:</strong> Instead of doing separate t-tests
(which ignore the ANOVA), emmeans uses the <strong>fitted ANOVA
model</strong> to estimate group means and make comparisons.</p>
</div>
<div id="section-adjustment-methods-whats-the-difference"
class="section level3">
<h3>Adjustment Methods: What’s the Difference?</h3>
<p>There are several methods for adjusting p-values in multiple
comparisons. Each makes different trade-offs between conservativeness
and power:</p>
<div id="section-bonferroni-correction" class="section level4">
<h4>1. Bonferroni Correction</h4>
<p><strong>Method:</strong> Multiply each p-value by the number of
comparisons (or equivalently, divide α by the number of comparisons)</p>
<p><span class="math display">\[p_{\text{adjusted}} = p \times k \quad
\text{or} \quad \alpha^* = \frac{\alpha}{k}\]</span></p>
<p><strong>Pros:</strong> - Very simple to understand and calculate -
Controls FWER (family-wise error rate) strictly - Works for any type of
comparisons</p>
<p><strong>Cons:</strong> - Very conservative (loses power) - Treats all
comparisons as equally important - Can miss real differences when doing
many tests</p>
<p><strong>When to use:</strong> When you want strict control over Type
I errors and have relatively few comparisons</p>
</div>
<div id="section-holm-method-sequential-bonferroni"
class="section level4">
<h4>2. Holm Method (Sequential Bonferroni)</h4>
<p><strong>Method:</strong> Order p-values from smallest to largest,
then apply decreasing adjustments</p>
<ol style="list-style-type: decimal">
<li>Multiply smallest p-value by k</li>
<li>Multiply second smallest by k-1</li>
<li>Continue until all adjusted</li>
<li>Ensure monotonicity (adjusted p-values never decrease)</li>
</ol>
<p><strong>Pros:</strong> - Always more powerful than Bonferroni - Still
controls FWER strictly - Nearly as easy to understand</p>
<p><strong>Cons:</strong> - Still somewhat conservative - Requires
ordering comparisons</p>
<p><strong>When to use:</strong> Default choice for FWER
control—uniformly better than Bonferroni!</p>
</div>
<div id="section-fdr-false-discovery-rate---benjamini-hochberg"
class="section level4">
<h4>3. FDR (False Discovery Rate) - Benjamini &amp; Hochberg</h4>
<p><strong>Method:</strong> Controls the expected proportion of false
discoveries among rejected hypotheses</p>
<p>Instead of controlling: “What’s the probability of ANY false
positive?” (FWER)</p>
<p>Controls: “What proportion of our ‘discoveries’ are false?” (FDR)</p>
<p><strong>Pros:</strong> - Much more powerful than Bonferroni/Holm -
Appropriate for exploratory analysis - Good when doing many
comparisons</p>
<p><strong>Cons:</strong> - Allows some false positives (by design) -
Less strict control than FWER methods - Requires more explanation</p>
<p><strong>When to use:</strong> When you have many comparisons and can
tolerate some false positives, especially in exploratory research</p>
</div>
<div id="section-tukey-hsd-honestly-significant-difference"
class="section level4">
<h4>4. Tukey HSD (Honestly Significant Difference)</h4>
<p><strong>Method:</strong> Uses the studentized range distribution (q)
to adjust for multiple comparisons</p>
<p><strong>Specifically designed for pairwise comparisons in
ANOVA</strong></p>
<p><strong>Pros:</strong> - Optimal for <strong>all pairwise
comparisons</strong> in ANOVA - More powerful than Bonferroni for this
specific case - Gold standard for balanced designs - Provides
simultaneous confidence intervals</p>
<p><strong>Cons:</strong> - Only works for pairwise comparisons -
Slightly more complex calculation - Assumes equal sample sizes work best
(but handles unequal sizes)</p>
<p><strong>When to use:</strong> When you want to compare <strong>all
pairs</strong> of groups after ANOVA—this is the standard choice!</p>
</div>
</div>
<div id="section-comparison-summary-table" class="section level3">
<h3>Comparison Summary Table</h3>
<table>
<colgroup>
<col width="20%" />
<col width="25%" />
<col width="17%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Controls</th>
<th>Power</th>
<th>Best Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Bonferroni</strong></td>
<td>FWER</td>
<td>Lowest</td>
<td>Few comparisons, need simplicity</td>
</tr>
<tr class="even">
<td><strong>Holm</strong></td>
<td>FWER</td>
<td>Low-Medium</td>
<td>General purpose, better than Bonferroni</td>
</tr>
<tr class="odd">
<td><strong>Tukey HSD</strong></td>
<td>FWER</td>
<td>Medium</td>
<td>All pairwise comparisons in ANOVA</td>
</tr>
<tr class="even">
<td><strong>FDR</strong></td>
<td>FDR</td>
<td>Highest</td>
<td>Many comparisons, exploratory research</td>
</tr>
</tbody>
</table>
<p>For our vocabulary ANOVA with 6 pairwise comparisons: - <strong>Tukey
HSD</strong> is probably the best choice (designed for this situation) -
<strong>Holm</strong> is a good alternative for strict FWER control -
<strong>FDR</strong> if we want maximum power -
<strong>Bonferroni</strong> is overly conservative but simple</p>
<p>Let’s try all four and compare!</p>
</div>
<div id="section-using-emmeans-step-by-step" class="section level3">
<h3>Using emmeans: Step by Step</h3>
<p>Let’s conduct post-hoc comparisons for the vocabulary ANOVA using
<code>emmeans</code>.</p>
<p><strong>Step 1:</strong> Fit the ANOVA model (we’ve already done
this!)</p>
<pre class="r"><code># Fit ANOVA model
vocab_aov &lt;- aov(wordsum ~ class, data = gss)</code></pre>
<p><strong>Step 2:</strong> Estimate marginal means for each social
class</p>
<pre class="r"><code># Estimate marginal means
vocab_means &lt;- emmeans(vocab_aov, specs = ~ class)
vocab_means</code></pre>
<pre><code>##  class   emmean     SE  df lower.CL upper.CL
##  LOWER     5.07 0.2970 791     4.49     5.66
##  MIDDLE    6.76 0.1050 791     6.56     6.97
##  UPPER     6.19 0.4760 791     5.25     7.12
##  WORKING   5.75 0.0944 791     5.56     5.93
## 
## Confidence level used: 0.95</code></pre>
<p><strong>Interpretation:</strong> These are the estimated mean
vocabulary scores for each social class, along with standard errors and
confidence intervals. Notice they’re based on the
<strong>model</strong>, not just raw group means.</p>
<p><strong>Step 3:</strong> Conduct pairwise comparisons with different
adjustments</p>
<p>Let’s compare all four methods side by side:</p>
<pre class="r"><code># All pairwise comparisons with different adjustments
pairs(vocab_means, adjust = &quot;bonferroni&quot;)</code></pre>
<pre><code>##  contrast         estimate    SE  df t.ratio p.value
##  LOWER - MIDDLE     -1.688 0.315 791  -5.353  &lt;.0001
##  LOWER - UPPER      -1.114 0.561 791  -1.985  0.2852
##  LOWER - WORKING    -0.676 0.312 791  -2.167  0.1833
##  MIDDLE - UPPER      0.574 0.488 791   1.177  1.0000
##  MIDDLE - WORKING    1.012 0.141 791   7.178  &lt;.0001
##  UPPER - WORKING     0.438 0.485 791   0.902  1.0000
## 
## P value adjustment: bonferroni method for 6 tests</code></pre>
<p>Now try the others! Let’s create a comparison of all four
methods.</p>
</div>
<div id="section-your-turn-compare-adjustment-methods"
class="section level3">
<h3>Your Turn: Compare Adjustment Methods</h3>
<p><strong>Your task:</strong> Run pairwise comparisons using all four
adjustment methods and compare the results.</p>
<p><strong>Steps:</strong></p>
<ol style="list-style-type: decimal">
<li>Fit the ANOVA model:
<code>vocab_aov &lt;- aov(wordsum ~ class, data = gss)</code></li>
<li>Get estimated marginal means:
<code>vocab_means &lt;- emmeans(vocab_aov, ~ class)</code></li>
<li>Run pairwise comparisons with each adjustment:
<ul>
<li><code>pairs(vocab_means, adjust = "bonferroni")</code></li>
<li><code>pairs(vocab_means, adjust = "holm")</code></li>
<li><code>pairs(vocab_means, adjust = "fdr")</code></li>
<li><code>pairs(vocab_means, adjust = "tukey")</code></li>
</ul></li>
</ol>
<div class="tutorial-exercise" data-label="vocabulary_5"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># Fit the ANOVA model
vocab_aov &lt;- aov(wordsum ~ class, data = gss)

# Estimate marginal means
vocab_means &lt;- emmeans(vocab_aov, ~ class)

# Bonferroni adjustment
pairs(vocab_means, adjust = &quot;bonferroni&quot;)

# Holm adjustment
pairs(vocab_means, adjust = &quot;holm&quot;)

# FDR adjustment  
pairs(vocab_means, adjust = &quot;fdr&quot;)

# Tukey HSD
pairs(vocab_means, adjust = &quot;tukey&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="vocabulary_5-hint"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># The code is already provided! Just run it.
# Compare the adjusted p-values across methods.
# Questions to consider:
# - Which method gives the smallest adjusted p-values?
# - Which comparisons are significant under each method?
# - How much do the adjustments differ?</code></pre>
</div>
<div class="tutorial-exercise-support"
data-label="vocabulary_5-solution" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code># Fit the ANOVA model
vocab_aov &lt;- aov(wordsum ~ class, data = gss)

# Estimate marginal means
vocab_means &lt;- emmeans(vocab_aov, ~ class)

# Bonferroni adjustment (most conservative)
cat(&quot;=== Bonferroni ===\n&quot;)
pairs(vocab_means, adjust = &quot;bonferroni&quot;)

# Holm adjustment (less conservative than Bonferroni)
cat(&quot;\n=== Holm ===\n&quot;)
pairs(vocab_means, adjust = &quot;holm&quot;)

# FDR adjustment (controls false discovery rate)
cat(&quot;\n=== FDR ===\n&quot;)
pairs(vocab_means, adjust = &quot;fdr&quot;)

# Tukey HSD (optimal for all pairwise comparisons)
cat(&quot;\n=== Tukey HSD ===\n&quot;)
pairs(vocab_means, adjust = &quot;tukey&quot;)

# Get a tidy version for easier comparison
cat(&quot;\n=== Tidy comparison table ===\n&quot;)
list(
  Bonferroni = pairs(vocab_means, adjust = &quot;bonferroni&quot;),
  Holm = pairs(vocab_means, adjust = &quot;holm&quot;),
  FDR = pairs(vocab_means, adjust = &quot;fdr&quot;),
  Tukey = pairs(vocab_means, adjust = &quot;tukey&quot;)
) |&gt;
  map_dfr(~ as_tibble(.x), .id = &quot;method&quot;) |&gt;
  select(method, contrast, estimate, p.value) |&gt;
  arrange(contrast, method)</code></pre>
</div>
</div>
<div id="section-interpreting-the-results" class="section level3">
<h3>Interpreting the Results</h3>
<p>Let’s compare what we found across all four methods.</p>
<p><strong>Key observations:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Estimate column:</strong> The estimated differences
between means are <strong>identical</strong> across all
methods—adjustment doesn’t change the estimates, only how we evaluate
them!</p></li>
<li><p><strong>P-value comparisons:</strong> Looking at adjusted
p-values from least to most conservative:</p>
<ul>
<li><strong>FDR:</strong> Most liberal (smallest adjusted p-values, most
discoveries)</li>
<li><strong>Tukey:</strong> Moderate</li>
<li><strong>Holm:</strong> More conservative</li>
<li><strong>Bonferroni:</strong> Most conservative (largest adjusted
p-values)</li>
</ul></li>
<li><p><strong>Significant comparisons:</strong> Which comparisons are
significant (p &lt; 0.05) under each method?</p>
<ul>
<li><strong>FDR:</strong> Most comparisons likely significant</li>
<li><strong>Tukey/Holm:</strong> Moderate number significant</li>
<li><strong>Bonferroni:</strong> Fewest significant (might miss real
differences)</li>
</ul></li>
</ol>
<p><strong>Practical question:</strong> Do the data provide convincing
evidence of a difference between the average vocabulary scores of:</p>
<ul>
<li><strong>Lower class vs. Upper class?</strong> → Check this
comparison!</li>
<li><strong>Middle class vs. Lower class?</strong> → Check this one
too!</li>
<li><strong>Working class vs. Middle class?</strong> → And this
one!</li>
</ul>
<p><strong>Your interpretation task:</strong></p>
<p>For each comparison, note: 1. The estimated difference in means 2.
Whether it’s significant (p &lt; 0.05) under each adjustment method 3.
What this tells us about vocabulary scores across social classes</p>
</div>
<div id="section-visualizing-the-comparisons" class="section level3">
<h3>Visualizing the Comparisons</h3>
<p>A plot can help us see which groups differ. Let’s visualize the
estimated means with confidence intervals:</p>
<pre class="r"><code># Plot estimated marginal means
plot(vocab_means) +
  labs(x = &quot;Estimated Mean Vocabulary Score&quot;,
       y = &quot;Social Class&quot;,
       title = &quot;Estimated Marginal Means with 95% CIs&quot;) +
  theme_minimal()</code></pre>
<p><img src="ims-anova_files/figure-html/unnamed-chunk-9-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><strong>How to read this plot:</strong></p>
<ul>
<li>Points show the estimated mean for each group</li>
<li>Horizontal lines show 95% confidence intervals</li>
<li>Groups whose CIs <strong>don’t overlap</strong> are likely
significantly different</li>
<li>Groups whose CIs <strong>do overlap</strong> might or might not be
different (need formal test)</li>
</ul>
<p><strong>Reflection:</strong> Looking at this plot, which groups
appear most different from each other? Does this match your statistical
test results?</p>
</div>
<div id="section-which-adjustment-should-you-use"
class="section level3">
<h3>Which Adjustment Should You Use?</h3>
<p><strong>General recommendations:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>For all pairwise comparisons in ANOVA:</strong> Use
<strong>Tukey HSD</strong> (the gold standard; also known as
Tukey-Kramer when sample sizes are unequal)</p></li>
<li><p><strong>For a small number of planned comparisons:</strong> Use
<strong>Holm</strong> (more powerful than traditional
Bonferroni)</p></li>
<li><p><strong>For many comparisons in exploratory research:</strong>
Use <strong>FDR</strong> (more power)</p></li>
<li><p><strong>When you need to explain to non-statisticians:</strong>
Use <strong>Bonferroni</strong> (simplest to explain, though overly
conservative)</p></li>
</ol>
<p><strong>For our vocabulary analysis:</strong> Tukey HSD is probably
the best choice since we’re comparing all pairs of groups after a
significant ANOVA.</p>
<p><strong>Important:</strong> Always <strong>pre-specify</strong> which
adjustment method you’ll use before looking at the data! Otherwise, you
might be tempted to choose the method that gives you the “best” results
(p-hacking).</p>
</div>
<div id="section-communicating-results" class="section level3">
<h3>Communicating Results</h3>
<p>When reporting post-hoc test results, include:</p>
<ol style="list-style-type: decimal">
<li><strong>Which method you used and why</strong>
<ul>
<li>“We used Tukey’s HSD adjustment to control the family-wise error
rate across all 6 pairwise comparisons.”</li>
</ul></li>
<li><strong>Significant findings</strong>
<ul>
<li>“We found significant differences between upper class and lower
class (p &lt; 0.001, d = 1.5 words) and between middle class and lower
class (p = 0.003, d = 0.9 words).”</li>
</ul></li>
<li><strong>Non-significant findings</strong> (especially if important!)
<ul>
<li>“We found no significant difference between working class and middle
class (p = 0.45).”</li>
</ul></li>
<li><strong>Effect sizes</strong>
<ul>
<li>Report actual differences in means, not just p-values</li>
<li>“On average, upper class respondents scored 1.5 words higher than
lower class respondents on the 10-word vocabulary test.”</li>
</ul></li>
</ol>
<p><strong>Remember:</strong> Statistical significance tells us if
differences are unlikely to be exactly <em>zero</em>. Practical
significance tells us if differences matter in the real world!</p>
</div>
</div>
<div id="section-congratulations" class="section level2">
<h2>Congratulations!</h2>
<p>You have successfully completed this tutorial!</p>
<p>You’re now ready to generate your submission hash. Click “Next Topic”
to proceed.</p>
</div>
<div id="section-submit" class="section level2">
<h2>Submit</h2>
<div class="encoder_ui">
<div>
If you have completed this tutorial and are happy with all of your
solutions, please enter your identifying information, then click the button below to generate your hash
<div class="form-group shiny-input-container">
<label class="control-label" id="name-label" for="name">What's your name?</label>
<input id="name" type="text" class="shiny-input-text form-control" value="" data-update-on="change"/>
</div>
<div class="form-group shiny-input-container">
<label class="control-label" id="studentID-label" for="studentID">What is your student ID?</label>
<input id="studentID" type="text" class="shiny-input-text form-control" value="" data-update-on="change"/>
</div>
<div id="out296cdd58eec00be2" class="shiny-text-output"></div>
</div>
<div class="row" style="padding-bottom: 0.5em;">
<div class="col-sm-3">
<button id="hash_generate" type="button" class="btn btn-default action-button" title="Generate hash">Generate</button>
</div>
<div class="col-sm-7"></div>
<div class="col-sm-2">
<div class="btn-group btn-group-sm pull-right" role="group" aria-label="Clipboard buttons">
<button id="hash_select" class="btn btn-default" type="button" title="Select hash"><svg
      aria-hidden="true" focusable="false"
      data-prefix="fas" data-icon="i-cursor"
      class="svg-inline--fa fa-i-cursor fa-w-8"
      role="img" xmlns="http://www.w3.org/2000/svg"
      viewBox="0 0 256 512" style="height: 16px;">
      <path fill="currentColor" d="M256 52.048V12.065C256 5.496 250.726.148 244.158.066 211.621-.344 166.469.011 128 37.959 90.266.736 46.979-.114 11.913.114 5.318.157 0 5.519 0 12.114v39.645c0 6.687 5.458 12.078 12.145 11.998C38.111 63.447 96 67.243 96 112.182V224H60c-6.627 0-12 5.373-12 12v40c0 6.627 5.373 12 12 12h36v112c0 44.932-56.075 48.031-83.95 47.959C5.404 447.942 0 453.306 0 459.952v39.983c0 6.569 5.274 11.917 11.842 11.999 32.537.409 77.689.054 116.158-37.894 37.734 37.223 81.021 38.073 116.087 37.845 6.595-.043 11.913-5.405 11.913-12V460.24c0-6.687-5.458-12.078-12.145-11.998C217.889 448.553 160 444.939 160 400V288h36c6.627 0 12-5.373 12-12v-40c0-6.627-5.373-12-12-12h-36V112.182c0-44.932 56.075-48.213 83.95-48.142 6.646.018 12.05-5.346 12.05-11.992z">
      </path>
    </svg></button>
<span class="btn-separator"></span>
<button id="hash_copy" class="btn btn-default" type="button" title="Copy hash to clipboard"><svg
      aria-hidden="true" focusable="false"
      data-prefix="far" data-icon="clipboard"
      class="svg-inline--fa fa-clipboard fa-w-12"
      role="img" xmlns="http://www.w3.org/2000/svg"
      viewBox="0 0 384 512" style="height: 16px;">
      <path fill="currentColor" d="M336 64h-80c0-35.3-28.7-64-64-64s-64 28.7-64 64H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 40c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm144 418c0 3.3-2.7 6-6 6H54c-3.3 0-6-2.7-6-6V118c0-3.3 2.7-6 6-6h42v36c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12v-36h42c3.3 0 6 2.7 6 6z">
      </path>
    </svg></button>
</div>
</div>
</div>
<pre id="hash_output" class="shiny-text-output" style="white-space: pre-wrap;"></pre>
<br/>
<script>selectText = function(node) {
        node = document.getElementById(node);

        if (document.body.createTextRange) {
          const range = document.body.createTextRange();
          range.moveToElementText(node);
          range.select();
        } else if (window.getSelection) {
          const selection = window.getSelection();
          const range = document.createRange();
          range.selectNodeContents(node);
          selection.removeAllRanges();
          selection.addRange(range);
        } else {
          console.warn('Could not select text in node: Unsupported browser.');
        }
      }</script>
<script>document.getElementById('hash_select').addEventListener('click', function(e) {
        e.preventDefault();

        selectText('hash_output');
      });</script>
<script>document.getElementById('hash_copy').addEventListener('click', function(e) {
        e.preventDefault();

        selectText('hash_output');
        document.execCommand('copy');
      });</script>
</div>
<p>
<script type="application/shiny-prerendered" data-context="server-start">
# load packages ----------------------------------------------------------------
library(learnr)
library(tidyverse)
library(infer)
library(broom)
library(emo)
library(openintro)
library(ggridges)
library(magrittr)
library(ggfortify)
library(emmeans)

# knitr options ----------------------------------------------------------------

knitr::opts_chunk$set(fig.align = "center", 
                      fig.height = 3, 
                      fig.width = 5,
                      echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE)

# data prep --------------------------------------------------------------------

gss <- read_csv("data/gss_wordsum_class.csv")

# Hash generation helpers
# Should ideally be loaded from the imstutorials package when it exists
is_server_context <- function(.envir) {
  # We are in the server context if there are the follow:
  # * input - input reactive values
  # * output - shiny output
  # * session - shiny session
  #
  # Check context by examining the class of each of these.
  # If any is missing then it will be a NULL which will fail.
  
  inherits(.envir$input, "reactivevalues") &
    inherits(.envir$output, "shinyoutput") &
    inherits(.envir$session, "ShinySession")
}

check_server_context <- function(.envir) {
  if (!is_server_context(.envir)) {
    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])
    err <- paste0("Function `", calling_func, "`", " must be called from an Rmd chunk where `context = \"server\"`")
    stop(err, call. = FALSE)
  }
}
encoder_logic <- function(strip_output = FALSE) {
  p <- parent.frame()
  check_server_context(p)
  # Make this var available within the local context below
  assign("strip_output", strip_output, envir = p)
  # Evaluate in parent frame to get input, output, and session
  local(
    {
      encoded_txt <- shiny::eventReactive(
        input$hash_generate,
        {
          # shiny::getDefaultReactiveDomain()$userData$tutorial_state
          state <- learnr:::get_tutorial_state()
          shiny::validate(shiny::need(length(state) > 0, "No progress yet."))
          shiny::validate(shiny::need(nchar(input$name) > 0, "No name entered."))
          shiny::validate(shiny::need(nchar(input$studentID) > 0, "Please enter your student ID"))
          user_state <- purrr::map_dfr(state, identity, .id = "label")
          user_state <- dplyr::group_by(user_state, label, type, correct)
          user_state <- dplyr::summarize(
            user_state,
            answer = list(answer),
            timestamp = dplyr::first(timestamp),
            .groups = "drop"
          )
          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)
          user_info <- tibble(
            label = c("student_name", "student_id"),
            type = "identifier",
            answer = as.list(c(input$name, input$studentID)),
            timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z", tz = "UTC")
          )
          learnrhash::encode_obj(bind_rows(user_info, user_state))
        }
      )
      output$hash_output <- shiny::renderText(encoded_txt())
    },
    envir = p
  )
}

hash_encoder_ui <- {
  shiny::div("If you have completed this tutorial and are happy with all of your", "solutions, please enter your identifying information, then click the button below to generate your hash", textInput("name", "What's your name?"), textInput("studentID", "What is your student ID?"), renderText({
    input$caption
  }), )
}
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-vocabulary-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-vocabulary-code-editor`)), session)
output$`tutorial-exercise-vocabulary-output` <- renderUI({
  `tutorial-exercise-vocabulary-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "vocabulary", global_setup = structure(c("# load packages ----------------------------------------------------------------", 
"library(learnr)", "library(tidyverse)", "library(infer)", "library(broom)", 
"library(emo)", "library(openintro)", "library(ggridges)", "library(magrittr)", 
"library(ggfortify)", "library(emmeans)", "", "# knitr options ----------------------------------------------------------------", 
"", "knitr::opts_chunk$set(fig.align = \"center\", ", "                      fig.height = 3, ", 
"                      fig.width = 5,", "                      echo = FALSE, ", 
"                      message = FALSE, ", "                      warning = FALSE)", 
"", "# data prep --------------------------------------------------------------------", 
"", "gss <- read_csv(\"data/gss_wordsum_class.csv\")", "", "# Hash generation helpers", 
"# Should ideally be loaded from the imstutorials package when it exists", 
"is_server_context <- function(.envir) {", "  # We are in the server context if there are the follow:", 
"  # * input - input reactive values", "  # * output - shiny output", 
"  # * session - shiny session", "  #", "  # Check context by examining the class of each of these.", 
"  # If any is missing then it will be a NULL which will fail.", 
"  ", "  inherits(.envir$input, \"reactivevalues\") &", "    inherits(.envir$output, \"shinyoutput\") &", 
"    inherits(.envir$session, \"ShinySession\")", "}", "", "check_server_context <- function(.envir) {", 
"  if (!is_server_context(.envir)) {", "    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])", 
"    err <- paste0(\"Function `\", calling_func, \"`\", \" must be called from an Rmd chunk where `context = \\\"server\\\"`\")", 
"    stop(err, call. = FALSE)", "  }", "}", "encoder_logic <- function(strip_output = FALSE) {", 
"  p <- parent.frame()", "  check_server_context(p)", "  # Make this var available within the local context below", 
"  assign(\"strip_output\", strip_output, envir = p)", "  # Evaluate in parent frame to get input, output, and session", 
"  local(", "    {", "      encoded_txt <- shiny::eventReactive(", 
"        input$hash_generate,", "        {", "          # shiny::getDefaultReactiveDomain()$userData$tutorial_state", 
"          state <- learnr:::get_tutorial_state()", "          shiny::validate(shiny::need(length(state) > 0, \"No progress yet.\"))", 
"          shiny::validate(shiny::need(nchar(input$name) > 0, \"No name entered.\"))", 
"          shiny::validate(shiny::need(nchar(input$studentID) > 0, \"Please enter your student ID\"))", 
"          user_state <- purrr::map_dfr(state, identity, .id = \"label\")", 
"          user_state <- dplyr::group_by(user_state, label, type, correct)", 
"          user_state <- dplyr::summarize(", "            user_state,", 
"            answer = list(answer),", "            timestamp = dplyr::first(timestamp),", 
"            .groups = \"drop\"", "          )", "          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)", 
"          user_info <- tibble(", "            label = c(\"student_name\", \"student_id\"),", 
"            type = \"identifier\",", "            answer = as.list(c(input$name, input$studentID)),", 
"            timestamp = format(Sys.time(), \"%Y-%m-%d %H:%M:%S %Z\", tz = \"UTC\")", 
"          )", "          learnrhash::encode_obj(bind_rows(user_info, user_state))", 
"        }", "      )", "      output$hash_output <- shiny::renderText(encoded_txt())", 
"    },", "    envir = p", "  )", "}", "", "hash_encoder_ui <- {", 
"  shiny::div(\"If you have completed this tutorial and are happy with all of your\", \"solutions, please enter your identifying information, then click the button below to generate your hash\", textInput(\"name\", \"What's your name?\"), textInput(\"studentID\", \"What is your student ID?\"), renderText({", 
"    input$caption", "  }), )", "}"), chunk_opts = list(label = "setup", 
    include = FALSE)), setup = NULL, chunks = list(list(label = "vocabulary", 
    code = "# Using gss, plot wordsum\nggplot(data = ___, mapping = aes(___)) +\n  # Add a histogram layer with appropriate binwidth\n  ___ +\n  # Facet by class\n  facet_wrap(~___)", 
    opts = list(label = "\"vocabulary\"", exercise = "TRUE"), 
    engine = "r")), code_check = NULL, error_check = NULL, check = NULL, 
    solution = structure(c("# Using gss, plot wordsum", "ggplot(data = gss, mapping = aes(x = wordsum)) +", 
    "  # Add a histogram layer", "  geom_histogram(binwidth = 1) +", 
    "  # Facet by class", "  facet_wrap(~class)"), chunk_opts = list(
        label = "vocabulary-solution")), tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "ims-anova_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "center", fig.path = "ims-anova_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 5, fig.height = 3, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 480, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = FALSE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, label = "vocabulary", exercise = TRUE, 
        code = c("# Using gss, plot wordsum", "ggplot(data = ___, mapping = aes(___)) +", 
        "  # Add a histogram layer with appropriate binwidth", 
        "  ___ +", "  # Facet by class", "  facet_wrap(~___)"
        ), out.width.px = 480, out.height.px = 288, params.src = "vocabulary, exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r", version = "4"), class = c("r", "tutorial_exercise"
)))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz_1", question = structure("Which panel shows groups with means that are MOST likely to be significantly different from each other? Which shows means LEAST likely to be different?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_27bf63f", 
    option = "Most likely: 1, least likely: 2", value = "Most likely: 1, least likely: 2", 
    label = structure("Most likely: 1, least likely: 2", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_4420ee5", 
    option = "Most likely: 1, least likely: 3", value = "Most likely: 1, least likely: 3", 
    label = structure("Most likely: 1, least likely: 3", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("Not quite. Look at Panel 2—the three boxplots are nearly identical and heavily overlapping. These are less likely to be significantly different than Panel 3.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_e1a5a7f", 
    option = "Most likely: 2, least likely: 3", value = "Most likely: 2, least likely: 3", 
    label = structure("Most likely: 2, least likely: 3", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("No. In Panel 2, the groups look very similar with lots of overlap—they’re unlikely to be significantly different.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_4bacecd", 
    option = "Most likely: 2, least likely: 1", value = "Most likely: 2, least likely: 1", 
    label = structure("Most likely: 2, least likely: 1", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("No. Groups that clearly differ from each other (with less overlap) are MORE likely to be significantly different.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Excellent! Panel 1 shows clear separation between groups with small within-group variability—the groups are most likely significantly different. Panel 2 shows very similar means with lots of overlap—least likely to be different.", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "quiz_1-answer", question = "quiz_1"), loading = NULL, 
    random_answer_order = FALSE, allow_retry = TRUE, seed = 1562966220.77219, 
    options = list()), class = c("learnr_radio", "tutorial_question"
)), session = session)
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-vocabulary_2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-vocabulary_2-code-editor`)), session)
output$`tutorial-exercise-vocabulary_2-output` <- renderUI({
  `tutorial-exercise-vocabulary_2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "vocabulary_2", global_setup = structure(c("# load packages ----------------------------------------------------------------", 
"library(learnr)", "library(tidyverse)", "library(infer)", "library(broom)", 
"library(emo)", "library(openintro)", "library(ggridges)", "library(magrittr)", 
"library(ggfortify)", "library(emmeans)", "", "# knitr options ----------------------------------------------------------------", 
"", "knitr::opts_chunk$set(fig.align = \"center\", ", "                      fig.height = 3, ", 
"                      fig.width = 5,", "                      echo = FALSE, ", 
"                      message = FALSE, ", "                      warning = FALSE)", 
"", "# data prep --------------------------------------------------------------------", 
"", "gss <- read_csv(\"data/gss_wordsum_class.csv\")", "", "# Hash generation helpers", 
"# Should ideally be loaded from the imstutorials package when it exists", 
"is_server_context <- function(.envir) {", "  # We are in the server context if there are the follow:", 
"  # * input - input reactive values", "  # * output - shiny output", 
"  # * session - shiny session", "  #", "  # Check context by examining the class of each of these.", 
"  # If any is missing then it will be a NULL which will fail.", 
"  ", "  inherits(.envir$input, \"reactivevalues\") &", "    inherits(.envir$output, \"shinyoutput\") &", 
"    inherits(.envir$session, \"ShinySession\")", "}", "", "check_server_context <- function(.envir) {", 
"  if (!is_server_context(.envir)) {", "    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])", 
"    err <- paste0(\"Function `\", calling_func, \"`\", \" must be called from an Rmd chunk where `context = \\\"server\\\"`\")", 
"    stop(err, call. = FALSE)", "  }", "}", "encoder_logic <- function(strip_output = FALSE) {", 
"  p <- parent.frame()", "  check_server_context(p)", "  # Make this var available within the local context below", 
"  assign(\"strip_output\", strip_output, envir = p)", "  # Evaluate in parent frame to get input, output, and session", 
"  local(", "    {", "      encoded_txt <- shiny::eventReactive(", 
"        input$hash_generate,", "        {", "          # shiny::getDefaultReactiveDomain()$userData$tutorial_state", 
"          state <- learnr:::get_tutorial_state()", "          shiny::validate(shiny::need(length(state) > 0, \"No progress yet.\"))", 
"          shiny::validate(shiny::need(nchar(input$name) > 0, \"No name entered.\"))", 
"          shiny::validate(shiny::need(nchar(input$studentID) > 0, \"Please enter your student ID\"))", 
"          user_state <- purrr::map_dfr(state, identity, .id = \"label\")", 
"          user_state <- dplyr::group_by(user_state, label, type, correct)", 
"          user_state <- dplyr::summarize(", "            user_state,", 
"            answer = list(answer),", "            timestamp = dplyr::first(timestamp),", 
"            .groups = \"drop\"", "          )", "          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)", 
"          user_info <- tibble(", "            label = c(\"student_name\", \"student_id\"),", 
"            type = \"identifier\",", "            answer = as.list(c(input$name, input$studentID)),", 
"            timestamp = format(Sys.time(), \"%Y-%m-%d %H:%M:%S %Z\", tz = \"UTC\")", 
"          )", "          learnrhash::encode_obj(bind_rows(user_info, user_state))", 
"        }", "      )", "      output$hash_output <- shiny::renderText(encoded_txt())", 
"    },", "    envir = p", "  )", "}", "", "hash_encoder_ui <- {", 
"  shiny::div(\"If you have completed this tutorial and are happy with all of your\", \"solutions, please enter your identifying information, then click the button below to generate your hash\", textInput(\"name\", \"What's your name?\"), textInput(\"studentID\", \"What is your student ID?\"), renderText({", 
"    input$caption", "  }), )", "}"), chunk_opts = list(label = "setup", 
    include = FALSE)), setup = NULL, chunks = list(list(label = "vocabulary_2", 
    code = "# Run an analysis of variance on score vs. rank\naov_evals_rank <- aov(___, data = ___)\n\n# Tidy the model\ntidy(___)", 
    opts = list(label = "\"vocabulary_2\"", exercise = "TRUE"), 
    engine = "r")), code_check = NULL, error_check = NULL, check = NULL, 
    solution = structure(c("# Run an analysis of variance on score vs. rank", 
    "aov_evals_rank <- aov(score ~ rank, data = evals)", "", 
    "# Tidy the model", "tidy(aov_evals_rank)"), chunk_opts = list(
        label = "vocabulary_2-solution")), tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "ims-anova_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "center", fig.path = "ims-anova_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 5, fig.height = 3, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 480, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = FALSE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, label = "vocabulary_2", exercise = TRUE, 
        code = c("# Run an analysis of variance on score vs. rank", 
        "aov_evals_rank <- aov(___, data = ___)", "", "# Tidy the model", 
        "tidy(___)"), out.width.px = 480, out.height.px = 288, 
        params.src = "vocabulary_2, exercise=TRUE", fig.num = 0, 
        exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r", version = "4"), class = c("r", "tutorial_exercise"
)))
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz_2", question = structure("Which of the following provides the MOST complete information for checking the normality condition for the vocabulary score ANOVA?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_2c4587f", 
    option = "Violin plot of vocabulary scores, faceted by social class", 
    value = "Violin plot of vocabulary scores, faceted by social class", 
    label = structure("Violin plot of vocabulary scores, faceted by social class", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_fd8fc8b", 
    option = "Boxplot of vocabulary scores, faceted by social class", 
    value = "Boxplot of vocabulary scores, faceted by social class", 
    label = structure("Boxplot of vocabulary scores, faceted by social class", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("Boxplots are useful, but they only show 5 summary statistics (median, quartiles, min/max) plus outliers. They don’t show the full shape of the distribution, so you can’t fully assess normality.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_faf0d10", 
    option = "Means and standard deviations of vocabulary scores in each social class", 
    value = "Means and standard deviations of vocabulary scores in each social class", 
    label = structure("Means and standard deviations of vocabulary scores in each social class", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("These are just two numbers—they don’t tell you anything about the shape of the distribution. A symmetric distribution and a skewed distribution could have the same mean and SD!", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_ac65d2c", 
    option = "Number of modes of vocabulary scores in each social class", 
    value = "Number of modes of vocabulary scores in each social class", 
    label = structure("Number of modes of vocabulary scores in each social class", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("Modality (one peak vs. multiple peaks) is just one aspect of shape. This doesn’t tell you about symmetry, outliers, or other features needed to assess normality.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Excellent! A violin plot shows the full shape of the distribution within each group, making it easy to assess normality visually. You can see symmetry, skewness, modality, and outliers all at once.", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "quiz_2-answer", question = "quiz_2"), loading = NULL, 
    random_answer_order = FALSE, allow_retry = TRUE, seed = 2139559695.00369, 
    options = list()), class = c("learnr_radio", "tutorial_question"
)), session = session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-vocabulary_3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-vocabulary_3-code-editor`)), session)
output$`tutorial-exercise-vocabulary_3-output` <- renderUI({
  `tutorial-exercise-vocabulary_3-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "vocabulary_3", global_setup = structure(c("# load packages ----------------------------------------------------------------", 
"library(learnr)", "library(tidyverse)", "library(infer)", "library(broom)", 
"library(emo)", "library(openintro)", "library(ggridges)", "library(magrittr)", 
"library(ggfortify)", "library(emmeans)", "", "# knitr options ----------------------------------------------------------------", 
"", "knitr::opts_chunk$set(fig.align = \"center\", ", "                      fig.height = 3, ", 
"                      fig.width = 5,", "                      echo = FALSE, ", 
"                      message = FALSE, ", "                      warning = FALSE)", 
"", "# data prep --------------------------------------------------------------------", 
"", "gss <- read_csv(\"data/gss_wordsum_class.csv\")", "", "# Hash generation helpers", 
"# Should ideally be loaded from the imstutorials package when it exists", 
"is_server_context <- function(.envir) {", "  # We are in the server context if there are the follow:", 
"  # * input - input reactive values", "  # * output - shiny output", 
"  # * session - shiny session", "  #", "  # Check context by examining the class of each of these.", 
"  # If any is missing then it will be a NULL which will fail.", 
"  ", "  inherits(.envir$input, \"reactivevalues\") &", "    inherits(.envir$output, \"shinyoutput\") &", 
"    inherits(.envir$session, \"ShinySession\")", "}", "", "check_server_context <- function(.envir) {", 
"  if (!is_server_context(.envir)) {", "    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])", 
"    err <- paste0(\"Function `\", calling_func, \"`\", \" must be called from an Rmd chunk where `context = \\\"server\\\"`\")", 
"    stop(err, call. = FALSE)", "  }", "}", "encoder_logic <- function(strip_output = FALSE) {", 
"  p <- parent.frame()", "  check_server_context(p)", "  # Make this var available within the local context below", 
"  assign(\"strip_output\", strip_output, envir = p)", "  # Evaluate in parent frame to get input, output, and session", 
"  local(", "    {", "      encoded_txt <- shiny::eventReactive(", 
"        input$hash_generate,", "        {", "          # shiny::getDefaultReactiveDomain()$userData$tutorial_state", 
"          state <- learnr:::get_tutorial_state()", "          shiny::validate(shiny::need(length(state) > 0, \"No progress yet.\"))", 
"          shiny::validate(shiny::need(nchar(input$name) > 0, \"No name entered.\"))", 
"          shiny::validate(shiny::need(nchar(input$studentID) > 0, \"Please enter your student ID\"))", 
"          user_state <- purrr::map_dfr(state, identity, .id = \"label\")", 
"          user_state <- dplyr::group_by(user_state, label, type, correct)", 
"          user_state <- dplyr::summarize(", "            user_state,", 
"            answer = list(answer),", "            timestamp = dplyr::first(timestamp),", 
"            .groups = \"drop\"", "          )", "          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)", 
"          user_info <- tibble(", "            label = c(\"student_name\", \"student_id\"),", 
"            type = \"identifier\",", "            answer = as.list(c(input$name, input$studentID)),", 
"            timestamp = format(Sys.time(), \"%Y-%m-%d %H:%M:%S %Z\", tz = \"UTC\")", 
"          )", "          learnrhash::encode_obj(bind_rows(user_info, user_state))", 
"        }", "      )", "      output$hash_output <- shiny::renderText(encoded_txt())", 
"    },", "    envir = p", "  )", "}", "", "hash_encoder_ui <- {", 
"  shiny::div(\"If you have completed this tutorial and are happy with all of your\", \"solutions, please enter your identifying information, then click the button below to generate your hash\", textInput(\"name\", \"What's your name?\"), textInput(\"studentID\", \"What is your student ID?\"), renderText({", 
"    input$caption", "  }), )", "}"), chunk_opts = list(label = "setup", 
    include = FALSE)), setup = NULL, chunks = list(list(label = "vocabulary_3", 
    code = "gss |>\n  # Group by class\n  group_by(___) |>\n  # Calculate the std dev of wordsum as sd_wordsum\n  summarize(___ = ___)", 
    opts = list(label = "\"vocabulary_3\"", exercise = "TRUE"), 
    engine = "r")), code_check = NULL, error_check = NULL, check = NULL, 
    solution = structure(c("gss |>", "  # Group by class", "  group_by(class) |>", 
    "  # Calculate the std dev of wordsum as sd_wordsum", "  summarize(sd_wordsum = sd(wordsum))"
    ), chunk_opts = list(label = "vocabulary_3-solution")), tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "ims-anova_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "ims-anova_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 5, fig.height = 3, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 480, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = FALSE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, label = "vocabulary_3", exercise = TRUE, 
        code = c("gss |>", "  # Group by class", "  group_by(___) |>", 
        "  # Calculate the std dev of wordsum as sd_wordsum", 
        "  summarize(___ = ___)"), out.width.px = 480, out.height.px = 288, 
        params.src = "vocabulary_3, exercise=TRUE", fig.num = 0, 
        exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r", version = "4"), class = c("r", "tutorial_exercise"
)))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-vocabulary_4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-vocabulary_4-code-editor`)), session)
output$`tutorial-exercise-vocabulary_4-output` <- renderUI({
  `tutorial-exercise-vocabulary_4-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "vocabulary_4", global_setup = structure(c("# load packages ----------------------------------------------------------------", 
"library(learnr)", "library(tidyverse)", "library(infer)", "library(broom)", 
"library(emo)", "library(openintro)", "library(ggridges)", "library(magrittr)", 
"library(ggfortify)", "library(emmeans)", "", "# knitr options ----------------------------------------------------------------", 
"", "knitr::opts_chunk$set(fig.align = \"center\", ", "                      fig.height = 3, ", 
"                      fig.width = 5,", "                      echo = FALSE, ", 
"                      message = FALSE, ", "                      warning = FALSE)", 
"", "# data prep --------------------------------------------------------------------", 
"", "gss <- read_csv(\"data/gss_wordsum_class.csv\")", "", "# Hash generation helpers", 
"# Should ideally be loaded from the imstutorials package when it exists", 
"is_server_context <- function(.envir) {", "  # We are in the server context if there are the follow:", 
"  # * input - input reactive values", "  # * output - shiny output", 
"  # * session - shiny session", "  #", "  # Check context by examining the class of each of these.", 
"  # If any is missing then it will be a NULL which will fail.", 
"  ", "  inherits(.envir$input, \"reactivevalues\") &", "    inherits(.envir$output, \"shinyoutput\") &", 
"    inherits(.envir$session, \"ShinySession\")", "}", "", "check_server_context <- function(.envir) {", 
"  if (!is_server_context(.envir)) {", "    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])", 
"    err <- paste0(\"Function `\", calling_func, \"`\", \" must be called from an Rmd chunk where `context = \\\"server\\\"`\")", 
"    stop(err, call. = FALSE)", "  }", "}", "encoder_logic <- function(strip_output = FALSE) {", 
"  p <- parent.frame()", "  check_server_context(p)", "  # Make this var available within the local context below", 
"  assign(\"strip_output\", strip_output, envir = p)", "  # Evaluate in parent frame to get input, output, and session", 
"  local(", "    {", "      encoded_txt <- shiny::eventReactive(", 
"        input$hash_generate,", "        {", "          # shiny::getDefaultReactiveDomain()$userData$tutorial_state", 
"          state <- learnr:::get_tutorial_state()", "          shiny::validate(shiny::need(length(state) > 0, \"No progress yet.\"))", 
"          shiny::validate(shiny::need(nchar(input$name) > 0, \"No name entered.\"))", 
"          shiny::validate(shiny::need(nchar(input$studentID) > 0, \"Please enter your student ID\"))", 
"          user_state <- purrr::map_dfr(state, identity, .id = \"label\")", 
"          user_state <- dplyr::group_by(user_state, label, type, correct)", 
"          user_state <- dplyr::summarize(", "            user_state,", 
"            answer = list(answer),", "            timestamp = dplyr::first(timestamp),", 
"            .groups = \"drop\"", "          )", "          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)", 
"          user_info <- tibble(", "            label = c(\"student_name\", \"student_id\"),", 
"            type = \"identifier\",", "            answer = as.list(c(input$name, input$studentID)),", 
"            timestamp = format(Sys.time(), \"%Y-%m-%d %H:%M:%S %Z\", tz = \"UTC\")", 
"          )", "          learnrhash::encode_obj(bind_rows(user_info, user_state))", 
"        }", "      )", "      output$hash_output <- shiny::renderText(encoded_txt())", 
"    },", "    envir = p", "  )", "}", "", "hash_encoder_ui <- {", 
"  shiny::div(\"If you have completed this tutorial and are happy with all of your\", \"solutions, please enter your identifying information, then click the button below to generate your hash\", textInput(\"name\", \"What's your name?\"), textInput(\"studentID\", \"What is your student ID?\"), renderText({", 
"    input$caption", "  }), )", "}"), chunk_opts = list(label = "setup", 
    include = FALSE)), setup = NULL, chunks = list(list(label = "vocabulary_4", 
    code = "gss |>\n  # Map wordsum to the x-axis and class to the y-axis\n  ggplot(aes(x = ___, y = ___)) +\n  # Add density ridges to the plot! \n  geom_density_ridges()", 
    opts = list(label = "\"vocabulary_4\"", exercise = "TRUE"), 
    engine = "r")), code_check = NULL, error_check = NULL, check = NULL, 
    solution = structure(c("gss |>", "  # Map wordsum to the x-axis and class to the y-axis", 
    "  ggplot(aes(x = wordsum, y = class)) +", "  # Add density ridges to the plot! ", 
    "  geom_density_ridges()"), chunk_opts = list(label = "vocabulary_4-solution")), 
    tests = NULL, options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "ims-anova_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "ims-anova_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 5, fig.height = 3, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 480, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = FALSE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, label = "vocabulary_4", exercise = TRUE, 
        code = c("gss |>", "  # Map wordsum to the x-axis and class to the y-axis", 
        "  ggplot(aes(x = ___, y = ___)) +", "  # Add density ridges to the plot! ", 
        "  geom_density_ridges()"), out.width.px = 480, out.height.px = 288, 
        params.src = "vocabulary_4, exercise=TRUE", fig.num = 0, 
        exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r", version = "4"), class = c("r", "tutorial_exercise"
)))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-vocabulary_5-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-vocabulary_5-code-editor`)), session)
output$`tutorial-exercise-vocabulary_5-output` <- renderUI({
  `tutorial-exercise-vocabulary_5-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "vocabulary_5", global_setup = structure(c("# load packages ----------------------------------------------------------------", 
"library(learnr)", "library(tidyverse)", "library(infer)", "library(broom)", 
"library(emo)", "library(openintro)", "library(ggridges)", "library(magrittr)", 
"library(ggfortify)", "library(emmeans)", "", "# knitr options ----------------------------------------------------------------", 
"", "knitr::opts_chunk$set(fig.align = \"center\", ", "                      fig.height = 3, ", 
"                      fig.width = 5,", "                      echo = FALSE, ", 
"                      message = FALSE, ", "                      warning = FALSE)", 
"", "# data prep --------------------------------------------------------------------", 
"", "gss <- read_csv(\"data/gss_wordsum_class.csv\")", "", "# Hash generation helpers", 
"# Should ideally be loaded from the imstutorials package when it exists", 
"is_server_context <- function(.envir) {", "  # We are in the server context if there are the follow:", 
"  # * input - input reactive values", "  # * output - shiny output", 
"  # * session - shiny session", "  #", "  # Check context by examining the class of each of these.", 
"  # If any is missing then it will be a NULL which will fail.", 
"  ", "  inherits(.envir$input, \"reactivevalues\") &", "    inherits(.envir$output, \"shinyoutput\") &", 
"    inherits(.envir$session, \"ShinySession\")", "}", "", "check_server_context <- function(.envir) {", 
"  if (!is_server_context(.envir)) {", "    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])", 
"    err <- paste0(\"Function `\", calling_func, \"`\", \" must be called from an Rmd chunk where `context = \\\"server\\\"`\")", 
"    stop(err, call. = FALSE)", "  }", "}", "encoder_logic <- function(strip_output = FALSE) {", 
"  p <- parent.frame()", "  check_server_context(p)", "  # Make this var available within the local context below", 
"  assign(\"strip_output\", strip_output, envir = p)", "  # Evaluate in parent frame to get input, output, and session", 
"  local(", "    {", "      encoded_txt <- shiny::eventReactive(", 
"        input$hash_generate,", "        {", "          # shiny::getDefaultReactiveDomain()$userData$tutorial_state", 
"          state <- learnr:::get_tutorial_state()", "          shiny::validate(shiny::need(length(state) > 0, \"No progress yet.\"))", 
"          shiny::validate(shiny::need(nchar(input$name) > 0, \"No name entered.\"))", 
"          shiny::validate(shiny::need(nchar(input$studentID) > 0, \"Please enter your student ID\"))", 
"          user_state <- purrr::map_dfr(state, identity, .id = \"label\")", 
"          user_state <- dplyr::group_by(user_state, label, type, correct)", 
"          user_state <- dplyr::summarize(", "            user_state,", 
"            answer = list(answer),", "            timestamp = dplyr::first(timestamp),", 
"            .groups = \"drop\"", "          )", "          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)", 
"          user_info <- tibble(", "            label = c(\"student_name\", \"student_id\"),", 
"            type = \"identifier\",", "            answer = as.list(c(input$name, input$studentID)),", 
"            timestamp = format(Sys.time(), \"%Y-%m-%d %H:%M:%S %Z\", tz = \"UTC\")", 
"          )", "          learnrhash::encode_obj(bind_rows(user_info, user_state))", 
"        }", "      )", "      output$hash_output <- shiny::renderText(encoded_txt())", 
"    },", "    envir = p", "  )", "}", "", "hash_encoder_ui <- {", 
"  shiny::div(\"If you have completed this tutorial and are happy with all of your\", \"solutions, please enter your identifying information, then click the button below to generate your hash\", textInput(\"name\", \"What's your name?\"), textInput(\"studentID\", \"What is your student ID?\"), renderText({", 
"    input$caption", "  }), )", "}"), chunk_opts = list(label = "setup", 
    include = FALSE)), setup = NULL, chunks = list(list(label = "vocabulary_5", 
    code = "# Fit the ANOVA model\nvocab_aov <- aov(wordsum ~ class, data = gss)\n\n# Estimate marginal means\nvocab_means <- emmeans(vocab_aov, ~ class)\n\n# Bonferroni adjustment\npairs(vocab_means, adjust = \"bonferroni\")\n\n# Holm adjustment\npairs(vocab_means, adjust = \"holm\")\n\n# FDR adjustment  \npairs(vocab_means, adjust = \"fdr\")\n\n# Tukey HSD\npairs(vocab_means, adjust = \"tukey\")", 
    opts = list(label = "\"vocabulary_5\"", exercise = "TRUE"), 
    engine = "r")), code_check = NULL, error_check = NULL, check = NULL, 
    solution = structure(c("# Fit the ANOVA model", "vocab_aov <- aov(wordsum ~ class, data = gss)", 
    "", "# Estimate marginal means", "vocab_means <- emmeans(vocab_aov, ~ class)", 
    "", "# Bonferroni adjustment (most conservative)", "cat(\"=== Bonferroni ===\\n\")", 
    "pairs(vocab_means, adjust = \"bonferroni\")", "", "# Holm adjustment (less conservative than Bonferroni)", 
    "cat(\"\\n=== Holm ===\\n\")", "pairs(vocab_means, adjust = \"holm\")", 
    "", "# FDR adjustment (controls false discovery rate)", "cat(\"\\n=== FDR ===\\n\")", 
    "pairs(vocab_means, adjust = \"fdr\")", "", "# Tukey HSD (optimal for all pairwise comparisons)", 
    "cat(\"\\n=== Tukey HSD ===\\n\")", "pairs(vocab_means, adjust = \"tukey\")", 
    "", "# Get a tidy version for easier comparison", "cat(\"\\n=== Tidy comparison table ===\\n\")", 
    "list(", "  Bonferroni = pairs(vocab_means, adjust = \"bonferroni\"),", 
    "  Holm = pairs(vocab_means, adjust = \"holm\"),", "  FDR = pairs(vocab_means, adjust = \"fdr\"),", 
    "  Tukey = pairs(vocab_means, adjust = \"tukey\")", ") |>", 
    "  map_dfr(~ as_tibble(.x), .id = \"method\") |>", "  select(method, contrast, estimate, p.value) |>", 
    "  arrange(contrast, method)"), chunk_opts = list(label = "vocabulary_5-solution")), 
    tests = NULL, options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "ims-anova_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "ims-anova_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 5, fig.height = 3, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 480, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = FALSE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, label = "vocabulary_5", exercise = TRUE, 
        code = c("# Fit the ANOVA model", "vocab_aov <- aov(wordsum ~ class, data = gss)", 
        "", "# Estimate marginal means", "vocab_means <- emmeans(vocab_aov, ~ class)", 
        "", "# Bonferroni adjustment", "pairs(vocab_means, adjust = \"bonferroni\")", 
        "", "# Holm adjustment", "pairs(vocab_means, adjust = \"holm\")", 
        "", "# FDR adjustment  ", "pairs(vocab_means, adjust = \"fdr\")", 
        "", "# Tukey HSD", "pairs(vocab_means, adjust = \"tukey\")"
        ), out.width.px = 480, out.height.px = 288, params.src = "vocabulary_5, exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r", version = "4"), class = c("r", "tutorial_exercise"
)))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
encoder_logic()
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.30"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.30"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.30"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.30"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.30"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalıştırma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"İpuçları\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki İpucu\",\"hintprev\":\"Önceki İpucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Baştan Başlamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabı onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Baştan Başlamak\",\"areyousure\":\"Baştan başlamak istediğinizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalısın\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sınav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"🏃\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"💡\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"🎯\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"📋\",\"startover\":\"⏮\",\"startovertitle\":\"Start Over\",\"continue\":\"✅\",\"submitanswer\":\"🆗\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"⬅\",\"nexttopic\":\"➡\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"🔁\"},\"text\":{\"startover\":\"⏮\",\"areyousure\":\"🤔\",\"youmustcomplete\":\"⚠️ 👉 🧑‍💻\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"💻\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"코드 실행\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"힌트\",\"hint_plural\":\"힌트들\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"다음 힌트\",\"hintprev\":\"이전 힌트\",\"solution\":\"솔루션\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"클립보드에 복사\",\"startover\":\"재학습\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"다음 학습으로\",\"submitanswer\":\"정답 제출\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"이전 토픽\",\"nexttopic\":\"다음 토픽\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"재시도\"},\"text\":{\"startover\":\"재학습\",\"areyousure\":\"다시 시작 하시겠습니까? (모든 예제의 진행 정보가 재설정됩니다)\",\"youmustcomplete\":\"당신은 완료해야 합니다\",\"exercise\":\"연습문제\",\"exercise_plural\":\"연습문제들\",\"inthissection\":\"이 섹션을 실행하기 전에\",\"code\":\"코드\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"퀴즈\",\"blank\":\"공백\",\"blank_plural\":\"공백들\",\"exercisecontainsblank\":\"이 연습문제에는 {{count}}개의 $t(text.blank)이 포함되어 있습니다.\",\"pleasereplaceblank\":\"{{blank}}를 유효한 코드로 바꾸십시오.\",\"unparsable\":\"이것은 유효한 R 코드가 아닐 수 있습니다. R은 텍스트를 완전한 명령으로 변환하는 방법을 결정할 수 없습니다. 당신은 공백이나 밑줄을 대체하여 채우기, 인수를 컴마로 구분하기, 또는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code>로 시작하는 구문을 닫는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code>을 잊었을 수도 있습니다.\\n\",\"and\":\"그리고\",\"or\":\"혹은\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"运行代码\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"提示\",\"hint_plural\":\"提示\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"下一个提示\",\"hintprev\":\"上一个提示\",\"solution\":\"答案\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"复制到剪切板\",\"startover\":\"重新开始\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"继续\",\"submitanswer\":\"提交答案\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"上一专题\",\"nexttopic\":\"下一专题\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"再试一次\"},\"text\":{\"startover\":\"重置\",\"areyousure\":\"你确定要重新开始吗? (所有当前进度将被重置)\",\"youmustcomplete\":\"你必须完成\",\"exercise\":\"练习\",\"exercise_plural\":\"练习\",\"inthissection\":\"在进行本节之前\",\"code\":\"代码\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"测试\",\"blank\":\"空\",\"blank_plural\":\"空\",\"exercisecontainsblank\":\"本练习包含{{count}}个$t(text.blank)\",\"pleasereplaceblank\":\"请在{{blank}}内填写恰当的代码\",\"unparsable\":\"这似乎不是有效的R代码。 R不知道如何将您的文本转换为完整的命令。 您是否忘了填空，忘了删除下划线，忘了在参数之间包含逗号，或者是忘了用<code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code>来封闭<code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code>。 or <code>{<\\/code>。\\n\",\"unparsablequotes\":\"<p>您的R代码中似乎含有特殊格式的引号，或者弯引号(<code>{{character}}<\\/code>) 在字符串前后，在R中字符串应该被直引号(<code>&quot;<\\/code> 或者 <code>'<\\/code>)包裹。<\\/p> {{code}} <p>别担心，该错误经常在复制粘贴包含格式的代码时遇到， 您可以尝试将该行中的代码替换为以下代码，也许还有其他地方需要修改。<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"and\":\"且\",\"or\":\"或\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedź\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Następna podpowiedź\",\"hintprev\":\"Poprzednia podpowiedź\",\"solution\":\"Rozwiązanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od początku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyślij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Następna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od początku\",\"areyousure\":\"Czy na pewno chcesz zacząć od początku? (cały postęp w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukończyć\",\"exercise\":\"ćwiczenie\",\"exercise_plural\":\"ćwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To ćwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Proszę uzupełnić {{blank}} prawidłowym kodem.\",\"unparsable\":\"Wygląda na to, że może to nie być prawidłowy kod R. R nie jest w stanie przetworzyć Twojego tekstu na polecenie. Mogłeś(-aś) zapomnieć wypełnić luki, usunąć podkreślnik, umieścić przecinka między argumentami, lub zamknąć znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadającym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wygląda na to, że Twój kod zawiera szczególnie sformatowane cudzysłowy lub cudzysłowy typograficzne (<code>{{character}}<\\/code>) przy ciągach znaków, co sprawia, że kod jest niepoprawny. R wymaga cudzysłowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw się, to powszechne źródło błędów, gdy kopiuje się kod z innego programu, który sam formatuje teskt. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Spróbuj usunąć znak specjalny i wpisać do ponownie ręcznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.11.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.30"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.30"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["6.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.min.css","css/v4-shims.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["fontawesome"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.5.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104]}},"value":[{"type":"character","attributes":{},"value":["airports","assertthat","backports","base","bit","bit64","broom","bslib","cachem","checkmate","cherryblossom","cli","coda","codetools","commonmark","compiler","crayon","datasets","digest","dplyr","ellipsis","emmeans","emo","estimability","evaluate","farver","fastmap","fontawesome","forcats","generics","ggfortify","ggplot2","ggridges","glue","graphics","grDevices","grid","gridExtra","gtable","hms","htmltools","htmlwidgets","httpuv","infer","jquerylib","jsonlite","knitr","labeling","later","lattice","learnr","learnrhash","lifecycle","litedown","lubridate","magrittr","markdown","MASS","Matrix","methods","mime","multcomp","mvtnorm","openintro","parallel","pillar","pkgconfig","promises","purrr","R6","RColorBrewer","Rcpp","readr","rlang","rmarkdown","rprojroot","rstudioapi","S7","sandwich","sass","scales","shiny","splines","stats","stringi","stringr","survival","TH.data","tibble","tidyr","tidyselect","tidyverse","timechange","tools","tzdb","usdata","utils","vctrs","vroom","withr","xfun","xtable","yaml","zoo"]},{"type":"character","attributes":{},"value":["0.1.0","0.2.1","1.5.0","4.5.1","4.6.0","4.6.0-1","1.0.9","0.9.0","1.1.0","2.3.3","0.1.0","3.6.5","0.19-4.1","0.2-20","2.0.0","4.5.1","1.5.3","4.5.1","0.6.37","1.1.4","0.3.2","1.11.2","0.0.0.9000","1.5.1","1.0.5","2.1.2","1.2.0","0.5.3","1.0.1","0.1.4","0.4.19","4.0.0","0.5.7","1.8.0","4.5.1","4.5.1","4.5.1","2.3","0.3.6","1.1.3","0.5.8.1","1.6.4","1.6.16","1.0.9","0.1.4","2.0.0","1.50","0.4.3","1.4.2","0.22-7","0.11.5","0.2.0","1.0.4","0.7","1.9.4","2.0.3","2.0","7.3-65","1.7-3","4.5.1","0.13","1.4-28","1.3-3","2.5.0","4.5.1","1.11.1","2.0.3","1.3.3","1.1.0","2.6.1","1.1-3","1.1.0","2.1.5","1.1.6","2.30","2.1.1","0.17.1","0.2.0","3.1-1","0.4.10","1.4.0","1.11.1","4.5.1","4.5.1","1.8.7","1.5.2","3.8-3","1.1-4","3.3.0","1.3.1","1.2.1","2.0.0","0.3.0","4.5.1","0.5.0","0.3.1","4.5.1","0.6.5","1.6.6","3.0.2","0.52","1.8-4","2.3.10","1.8-14"]}]}]}
</script>
<!--/html_preserve-->
</div>

</article> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h1 class="title toc-ignore" style="display:none;">Week 12: Comparing
many means with ANOVA</h1>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</main> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
