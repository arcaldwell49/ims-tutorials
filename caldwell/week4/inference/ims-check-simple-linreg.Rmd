---
title: "Week 4 (Part 2): Checking technical conditions for simple linear regression"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(broom)
library(dplyr)
library(ggplot2)
library(readr)
library(infer)
library(performance)
library(see)
library(ggfortify)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

REQUIRED_EXERCISES <- c(
  "ex41",
  "ex42",
  "ex43", "ex45",
  "ex415",
  "ex417"
)

# Load data from local files
hypdata_nonequalvar <- readRDS("data/movies03.rds") |>
  dplyr::select(response = box.office, explanatory = score)

starbucks <- readRDS("data/starbucks.rds")
starbucks_lowFib <- starbucks |> filter(fiber < 15)

# Generate simulated datasets for demonstrations
set.seed(47474)
explanatory <- rnorm(500)
epsilon <- rnorm(500, 0, 1.5)
response <- explanatory * 4.7 + 10 + epsilon
lineardata <- data.frame(explanatory, response)
linear_lm <- augment(lm(response ~ explanatory, data = lineardata))

response <- explanatory * 0.47 + 4.7 * explanatory^2 + 10 + epsilon
nonlineardata <- data.frame(explanatory, response)
nonlinear_lm <- augment(lm(response ~ explanatory, data = nonlineardata))

set.seed(47)
epsilon <- rbeta(500, shape1 = 1, shape2 = 10) * 10
response <- explanatory * 4.7 + 10 + epsilon
nonnormaldata <- data.frame(explanatory, response)
nonnormal_lm <- augment(lm(response ~ explanatory, data = nonnormaldata))

explanatory <- abs(explanatory)
response <- explanatory * 4.7 + 10 + epsilon * explanatory
nonequaldata <- data.frame(explanatory, response)
nonequal_lm <- augment(lm(response ~ explanatory, data = nonequaldata))

obs_slope <- lm(protein ~ fiber, starbucks) |>
  tidy() |>
  filter(term == "fiber") |>
  dplyr::select(estimate) |>
  pull() 

obs_slope_lowFib <- lm(protein ~ fiber, starbucks_lowFib) |>
  tidy() |>
  filter(term == "fiber") |>
  dplyr::select(estimate) |>
  pull() 

set.seed(4747)
perm_slope <- starbucks |>
  specify(protein ~ fiber) |>
  hypothesize("independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "slope")

set.seed(4747)
perm_slope_lowFib <- starbucks_lowFib |>
  specify(protein ~ fiber) |>
  hypothesize("independence") |>
  generate(reps = 1000, type = "permute") |>  
  calculate(stat = "slope")

n <- 100
beta0 <- 5
beta1 <- 0.1
set.seed(4747)
explanatory <- runif(n, 0, 3)
e <- rnorm(n, 0, 1)
data_nonlin <- data.frame(explanatory = explanatory, 
                          response = beta0 + beta1 * explanatory^2 + 2 * explanatory^2 + e)

n <- 100
beta0 <- 1
beta1 <- 2
set.seed(4747)
explanatory <- runif(n, 1, 4)
e <- rnorm(n, 0, 1)
data_nonnorm <- data.frame(explanatory = explanatory, 
                           response = exp(beta0 + beta1 * explanatory + e))

set.seed(4747)
hypdata_outlier <- tibble(explanatory = rnorm(200, 3, 1), 
                          response = explanatory * 3 + 12 + rnorm(200, 0, 2))
hypdata_outlier$response[47] <- 500

set.seed(4747)
hypdata_nice <- tibble(explanatory = rnorm(200, 3, 1), 
                       response = explanatory * 3 + 12 + rnorm(200, 0, 2))

set.seed(4747)
hypdata_poor <- tibble(explanatory = rnorm(200, 3, 1), 
                       response = explanatory * 3 + 12 + explanatory * rnorm(200, 0, 1))

set.seed(4747)
hypdata_outlier <- tibble(explanatory = rnorm(200, 3, 1),
                          response = explanatory * 3 + 12 + rnorm(200, 0, 2))
hypdata_outlier$response[47] <- 500
hypdata_no_outlier <- hypdata_outlier |> 
  filter(response < 200)

set.seed(4747)
explanatory <- rnorm(50, 3, 1)
response <- explanatory * 3 + 12 + rnorm(50, 0, 10)
response[47] <- 500
hypdata_out <- data.frame(explanatory, response)

obs_slope_out <- lm(response ~ explanatory, hypdata_out) |>
  tidy() |>
  filter(term == "explanatory") |>
  dplyr::select(estimate) |>
  pull() 

hypdata_noout <- hypdata_out |> filter(explanatory < 4.6) 

obs_slope_noout <- lm(response ~ explanatory, hypdata_noout) |>
  tidy() |>
  filter(term == "explanatory") |>
  dplyr::select(estimate) |>
  pull() 

set.seed(4747)
perm_slope_out <- hypdata_out |>
  specify(response ~ explanatory) |>
  hypothesize("independence") |>
  generate(reps = 500, type = "permute") |>
  calculate(stat = "slope")

set.seed(4747)
perm_slope_noout <- hypdata_noout |>
  specify(response ~ explanatory) |>
  hypothesize("independence") |>
  generate(reps = 500, type = "permute") |>  
  calculate(stat = "slope")

n <- 100
set.seed(4747)
hypdata_nonlinear <- tibble(
  explanatory = runif(n),
  response = 10 + 3 * explanatory + 15 * explanatory ^ 2 + rnorm(n)
)

n <- 100
set.seed(4747)
hypdata_nonnorm <- tibble(
  explanatory = runif(n),
  response = (10 + 10 * explanatory + rnorm(n, 0, 4)) ^ 2
)

# Hash generation helpers
is_server_context <- function(.envir) {
  inherits(.envir$input, "reactivevalues") &
    inherits(.envir$output, "shinyoutput") &
    inherits(.envir$session, "ShinySession")
}

check_server_context <- function(.envir) {
  if (!is_server_context(.envir)) {
    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])
    err <- paste0("Function `", calling_func, "`", " must be called from an Rmd chunk where `context = \"server\"`")
    stop(err, call. = FALSE)
  }
}

encoder_logic <- function(strip_output = FALSE) {
  p <- parent.frame()
  check_server_context(p)
  assign("strip_output", strip_output, envir = p)
  local(
    {
      encoded_txt <- shiny::eventReactive(
        input$hash_generate,
        {
          state <- learnr:::get_tutorial_state()
          shiny::validate(shiny::need(length(state) > 0, "No progress yet."))
          shiny::validate(shiny::need(nchar(input$name) > 0, "No name entered."))
          shiny::validate(shiny::need(nchar(input$studentID) > 0, "Please enter your student ID"))
          user_state <- purrr::map_dfr(state, identity, .id = "label")
          user_state <- dplyr::group_by(user_state, label, type, correct)
          user_state <- dplyr::summarize(
            user_state,
            answer = list(answer),
            timestamp = dplyr::first(timestamp),
            .groups = "drop"
          )
          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)
          user_info <- tibble(
            label = c("student_name", "student_id"),
            type = "identifier",
            answer = as.list(c(input$name, input$studentID)),
            timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z", tz = "UTC")
          )
          learnrhash::encode_obj(dplyr::bind_rows(user_info, user_state))
        }
      )
      output$hash_output <- shiny::renderText(encoded_txt())
    },
    envir = p
  )
}

# Progress checker logic
progress_checker_logic <- function() {
  p <- parent.frame()
  check_server_context(p)
  local(
    {
      # Reactive to check progress when button is clicked
      progress_info <- shiny::eventReactive(
        input$check_progress,
        {
          state <- learnr:::get_tutorial_state()
          
          # Get labels of completed exercises (any submission counts)
          completed_labels <- names(state)
          
          # Check which required exercises are completed
          completed_required <- REQUIRED_EXERCISES %in% completed_labels
          n_completed <- sum(completed_required)
          n_total <- length(REQUIRED_EXERCISES)
          pct <- round(100 * n_completed / n_total)
          
          # Find missing exercises
          missing <- REQUIRED_EXERCISES[!completed_required]
          
          list(
            n_completed = n_completed,
            n_total = n_total,
            pct = pct,
            missing = missing
          )
        }
      )
      
      # Render progress output
      output$progress_output <- shiny::renderUI({
        info <- progress_info()
        
        # Color based on completion
        bar_color <- if (info$pct == 100) "#28a745" else if (info$pct >= 50) "#ffc107" else "#dc3545"
        
        # Build missing exercises message
        if (length(info$missing) == 0) {
          missing_msg <- shiny::p(shiny::strong("All required exercises completed!"),
                                  style = "color: #28a745;")
        } else {
          missing_msg <- shiny::tagList(
            shiny::p(shiny::strong("Missing exercises:"), style = "margin-bottom: 5px;"),
            shiny::tags$ul(
              lapply(info$missing, function(x) shiny::tags$li(shiny::code(x)))
            )
          )
        }
        
        shiny::tagList(
          shiny::p(
            sprintf("Progress: %d / %d required exercises completed (%d%%)",
                    info$n_completed, info$n_total, info$pct)
          ),
          shiny::div(
            style = "background-color: #e9ecef; border-radius: 4px; height: 20px; margin-bottom: 10px;",
            shiny::div(
              style = sprintf("background-color: %s; width: %d%%; height: 100%%; border-radius: 4px; transition: width 0.3s;",
                              bar_color, info$pct)
            )
          ),
          missing_msg
        )
      })
    },
    envir = p
  )
}

hash_encoder_ui <- {
  shiny::div("If you have completed this tutorial and are happy with all of your", "solutions, please enter your identifying information, then click the button below to generate your hash", shiny::textInput("name", "What's your name?"), shiny::textInput("studentID", "What is your student ID?"), shiny::renderText({
    input$caption
  }), )
}
```

## Introduction

### Learning Objectives

By the end of this tutorial, you will be able to:

* Identify the four LINE conditions for linear regression
* Create and interpret residual plots to assess model assumptions
* Recognize violations of technical conditions in data visualizations
* Understand the impact of outliers on regression inference
* Apply appropriate transformations to address assumption violations

## Technical Conditions in linear regression

Additionally, you will consider the technical conditions that are important when using linear models to make claims about a larger population.

## Technical conditions for linear regression

In the previous lesson you saw that sometimes the mathematical model was not appropriate for inferential analysis (that is, for calculating p-values and confidence intervals).  In this lesson, we'll provide details for when the mathematical model is appropriate.

### What are the technical conditions?

When we fit a linear regression model, we assume the data follow this structure:

$$Y = \beta_0 + \beta_1 \cdot X + \epsilon$$
$$\epsilon \sim N(0, \sigma_\epsilon)$$ 

For valid statistical inference (accurate p-values and confidence intervals), four conditions must be met - remembered by the acronym **LINE**:

* **L**inear relationship between X and Y
* **I**ndependent observations 
* **N**ormally distributed residuals around the line 
* **E**qual variability (homoscedasticity) around the line for all X values

**Why do these matter?** If these conditions are violated, our p-values and confidence intervals may be misleading, potentially causing us to draw incorrect conclusions about relationships in our data.


```{r}
ggplot(lineardata, aes(x = explanatory, y = response)) + 
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)
```

Because your goal in this tutorial is to perform inferential calculations on the linear regression model, it is important that the sampling distribution for the estimated slope has the expected form.  That is, we will be able to apply our methods only if the points are linear, independent, normally distributed, and have equal variability around the line.  Note that the conditions are given by the linear model equation as well as spelled out using the LINE mnemonic.


If the sampling distribution isn't accurate, the p-values and confidence intervals that you calculate could be wrong.



### Linear model: residuals


```{r echo=TRUE, eval=FALSE}
linear_lm <- augment(
  lm(response ~ explanatory,
     data = lineardata)
)

ggplot(linear_lm, 
       aes(x = .fitted, 
           y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```


fitted value: 
$\hat{Y}_i = b_0 + b_1 X_i$

residual:
$e_i= Y_i - \hat{Y}_i$


```{r}
ggplot(linear_lm, aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0)
```

The `augment` function in the **broom** package calculates the fitted and residual values for every point in the dataset.  The output of the `augment` function defaults to `.fitted` and `.resid`.

If the linear model is appropriate, a plot of the residuals versus the fitted values should show a non-patterned scattering of the points.  The fitted model is usually described by Roman letters (b0 and b1), whereas the population model we want to find is described by Greek letters (beta0 and beta1).

The residual plot here (fitted value plotted on the x-axis, residual values plotted on the y-axis) shows a scattering of points which do not indicate any violation of the regression technical conditions.

### How to Read a Residual Plot

A **good** residual plot shows:
* Random scatter of points with no pattern
* Points roughly centered around the horizontal line at y = 0
* Consistent spread across all fitted values

**Warning signs** to look for:
* Curved patterns → nonlinearity
* Funnel shapes → unequal variance
* Asymmetric spread → many problems (non-normality)


### Not linear


$$Y = \beta_0 + \beta_1 \cdot X + \epsilon$$

$$\epsilon \sim N(0, \sigma_\epsilon)$$

* L: linear model
* I: independent observations
* N: points are normally distributed around the line
* E: equal variability around the line for all values of the explanatory variable


```{r}
ggplot(nonlineardata, aes(x = explanatory, y = response)) + geom_point()
```

The plot here demonstrates a clear violation of the linear model.  The variables have a quadratic relationship, not a linear one!



### Not linear: residuals


```{r echo=TRUE, eval=TRUE}
nonlinear_lm <- augment(
  lm(response ~ explanatory, data = nonlineardata)
)

ggplot(nonlinear_lm, 
       aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0)
```


fitted value: 
$\hat{Y}_i = b_0 + b_1 X_i$

residual:
$e_i= Y_i - \hat{Y}_i$


The residuals associated with the quadratic model also look curved.  For the technical conditions to hold, you need a non-patterned scattering of points.  Just like the original scatter plot, the residual plot with fitted value on the x-axis, and residual on the y-axis continues to demonstrates a violation of the linear technical condition.



### Not normal




$$Y = \beta_0 + \beta_1 \cdot X + \epsilon$$

$$\epsilon \sim N(0, \sigma_\epsilon)$$

* L: linear model
* I: independent observations
* N: points are normally distributed around the line
* E: equal variability around the line for all values of the explanatory variable

```{r}
ggplot(nonnormaldata, aes(x = explanatory, y = response)) + 
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)
```

The violation here is not as obvious as the non-linear violation.  In this plot, the points are not normally distributed around the line.  That is, although the residuals are centered at zero, the points under the line are closer to the line and the points above the line are scattered farther from the line.



### Not normal: residuals


```{r echo=TRUE, eval=FALSE}
nonnormal_lm <- augment(
  lm(response ~ explanatory, data = nonnormaldata)
  )

ggplot(nonnormal_lm, 
       aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0) 
```

fitted value: 
$\hat{Y}_i = b_0 + b_1 X_i$

residual:
$e_i= Y_i - \hat{Y}_i$


The residual plot makes it even easier to see the violation of the technical condition related to normality.  If the residuals were normally distributed around the line, they would be equally far from the line in the positive and negative direction.  Here, the points below the line do not spread out nearly as far as the points above the line.



### Not equal variance


$$Y = \beta_0 + \beta_1 \cdot X + \epsilon$$

$$\epsilon \sim N(0, \sigma_\epsilon)$$

* L: linear model
* I: independent observations
* N: points are normally distributed around the line
* E: equal variability around the line for all values of the explanatory variable


```{r}
ggplot(nonequaldata, aes(x = explanatory, y = response)) + 
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)
```


The last violation we will investigate is unequal variability across different values of the explanatory variable. In this plot, it seems as though the Y values associated with small X are quite close to the line whereas Y values associated with large values of X have a much larger variability around the line.



### Not equal variance: residuals

```{r echo=TRUE, eval=TRUE}
nonequal_lm <- augment(
  lm(response ~ explanatory, data = nonequaldata) 
)

ggplot(nonequal_lm, 
       aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0)
```

fitted value:

$\hat{Y}_i = b_0 + b_1 X_i$

residual:

$e_i= Y_i - \hat{Y}_i$


Once again, the residual plot accentuates the technical condition violation by demonstrating the increasing variability of the residuals around the line as the fitted value increases.

###  

As mentioned previously, meeting the technical conditions will help to ensure that your p-values and confidence interval estimates are an accurate reflection of your population values.  Up soon, you will practice transforming data so as to meet the conditions.  But for now, it is your turn to practice determining when the technical conditions have been met.


### Violation of LINE conditions (1)


Which of the linear regression technical conditions are violated in the given figure?


```{r echo=FALSE, message=FALSE, warning=FALSE}
n <- 100
beta0 <- 10
beta1 <- 3
x <- runif(n)
e <- rnorm(n)
ds <- data.frame(y = beta0 + beta1 * x + 15 * x^6 + e)
ggplot(ds, aes(x = x, y = y)) + geom_point()
```

Hint: These data do violate one of the technical conditions for *linear* regression.

```{r option-a1, echo=FALSE}
question("Which of the linear regression technical conditions are violated in the given figure?",
  answer("*L*inearity", correct = TRUE, message = "Right!  The variables do not show a linear relationship"),
  answer("*I*ndependence of errors", message = "No, this condition seems fine.  Try again."),
  answer("*N*ormality of the response variable around the line", message = "No, this condition seems fine.  Try again."),
  answer("*E*qual variability around the entire line", message = "No, this condition seems fine.  Try again."),
  answer("No technical conditions are violated", message = "The technical conditions are violated."),
  allow_retry = TRUE
)
```



### Violation of LINE conditions (2)


Which of the linear regression technical conditions are violated in the given figure?



```{r echo=FALSE, message=FALSE, warning=FALSE}
n <- 100
beta0 <- 10
beta1 <- 3
x <- runif(n)
e <- rnorm(n)
ds <- data.frame(y = beta0 + beta1 * x + e * x)
ggplot(ds, aes(x = x, y = y)) + geom_point()
```


Hint: These data do violate one of the conditions for linear regression. Look at the spread of the points around the line.


```{r option-c1, echo=FALSE}
question("Which of the linear regression technical conditions are violated in the given figure?",
  answer("*L*inearity", message = "No, this condition seems fine.  Try again."),
  answer("*I*ndependence of errors", message = "No, this condition seems fine.  Try again."),
  answer("*N*ormality of the response variable around the line", message = "No, this condition seems fine.  Try again."),
  answer("*E*qual variability around the entire line", message = "Right!  The variability around the line increases as the explanatory variable (X) increases.", correct = TRUE),
  answer("No technical conditions are violated", message = "The technical conditions are violated."),
  allow_retry = TRUE
)
```


### Moving from Theory to Practice

Now that you understand what violations look like, let's practice identifying them in real data. In the next exercises, you'll analyze residual plots and determine which LINE conditions are violated.


### Using residuals (1)

**Goal:** Practice creating residual plots to check LINE conditions.

When conditions are met, residual plots show random scatter with no discernible pattern. Let's see what this looks like with good data.

**Step 1:** First, visualize the relationship
Using `hypdata_nice`, draw a scatter plot of `response` versus `explanatory`.

In the next few exercises, you will calculate residuals from a data set that complies with the linear regression technical conditions.  For the linear model conditions to hold, the points should be scattered throughout the residual plot with no discernible pattern.  Here, the residual plot looks like a scattering of points.



Using `hypdata_nice`, draw a scatter plot of `response` versus `explanatory`.



```{r ex41, exercise=TRUE, exercise.cap = "ex41"}
# Using hypdata_nice, draw a scatter plot of response vs. explanatory
___
```

```{r ex41-hint}
- Call `ggplot()` with `hypdata_nice` as the data.
- Inside `aes()`, map `x` to `explanatory` and `y` to `response`.
- Add `geom_point()`.
```


```{r ex41-solution}
# Using hypdata_nice, draw a scatter plot of response vs. explanatory
ggplot(hypdata_nice, aes(x = explanatory, y = response)) + 
  geom_point()
```



**Step 2:** Now check the residuals


- Run a linear regression of `response` versus `explanatory` on `hypdata_nice`.
- Get the observation-level information from the model using `augment`.
- Using `modeled_observations`, plot `.resid` vs. `.fitted` and add a point layer.


```{r ex42, exercise=TRUE, exercise.cap = "ex42"}
# Run a linear regression of response vs. explanatory
model <- ___

# Augment to get the observation-level information
modeled_observations <- ___

# See the result
modeled_observations

# Using modeled_observations, draw a scatter plot of .resid vs. .fitted
___
```


```{r ex42-hint}
- Call `lm()`, modeling `response` versus `explanatory` and setting the data to `hypdata_nice`.
- Call `augment()` to get the observation-level information from the model.
- Use `modeled_observations` as `ggplot()`'s data argument. Inside `aes()`, map `x` to `.fitted` and `y` to `.resid`.
- Add `geom_point()`.
```




```{r ex42-solution}
# Run a linear regression of response vs. explanatory
model <- lm(response ~ explanatory, data = hypdata_nice)

# Augment to get the observation-level information
modeled_observations <- augment(model)

# See the result
modeled_observations

# Using modeled_observations, draw a scatter plot of .resid vs. .fitted
ggplot(modeled_observations, aes(x = .fitted, y = .resid)) + 
  geom_point()
```




### Using residuals (2)


Now, you will calculate residuals from a data set that violates the technical conditions.  For the linear model conditions to hold, the points should be scattered throughout the residual plot with no discernible pattern.  Here the residuals reveal a violation of the technical conditions.



Using `hypdata_poor`, draw a scatter plot of `response` versus `explanatory`.



```{r ex43, exercise=TRUE, exercise.cap = "ex43"}
# Using hypdata_poor, draw a scatter plot of response vs. explanatory
___
```


```{r ex43-hint}
- Call `ggplot()` with `hypdata_poor` as the data.
- Inside `aes()`, map `x` to `explanatory` and `y` to `response`.
- Add `geom_point()`.
```


```{r ex43-solution}
# Using hypdata_poor, draw a scatter plot of response vs. explanatory
ggplot(hypdata_poor, aes(x = explanatory, y = response)) + 
  geom_point()
```







- Run a linear regression of `response` versus `explanatory` on `hypdata_poor`.
- Get the observation-level information from the model using `augment`.
- Using `modeled_observations`, plot residuals vs. fitted values and add a point layer.



```{r ex45, exercise=TRUE, exercise.cap = "ex45"}
# Run a linear regression of response vs. explanatory
model <- ___

# Augment to get the observation-level information
modeled_observations <- ___

# See the result
modeled_observations

# Using modeled_observations, draw a scatter plot 
# of residuals vs. fitted values
___
```



```{r ex45-hint}
- Call `lm()`, modeling `response` versus `explanatory` and setting the data to `hypdata_poor`.
- Call `augment()` to get the observation-level information from the model.
- Use `modeled_observations` as `ggplot()`'s data argument. Inside `aes()`, map `x` to `.fitted` and `y` to `.resid`.
- Add `geom_point()`.
```


```{r ex45-solution}
# Run a linear regression of response vs. explanatory
model <- lm(response ~ explanatory, data = hypdata_poor)

# Augment to get the observation-level information
modeled_observations <- augment(model)

# See the result
modeled_observations

# Using modeled_observations, draw a scatter plot 
# of residuals vs. fitted values
ggplot(modeled_observations, aes(x = .fitted, y = .resid)) + 
  geom_point()
```



### Why do we need the LINE assumptions?


So far, you have implemented two approaches for performing inference assessment to a linear model.  The first way is given by the standard R output (`lm`) and is based on the t-distribution.  The derivation of the t-distribution is based on the theory (i.e., the LINE conditions).  

The second method uses a randomization (permutation) test which assumes that the observations are exchangeable under the null hypothesis. That is, when the null hypothesis (X is independent of Y) is true, the Y values can be swapped among the X values.  The technical conditions in the randomization setting are linear relationship, independent observations, and equal variances.  However, the normality assumption is not needed. However, this type of test is beyond the scope of this course.

What happens if inferences is performed when the technical conditions are violated?

Hint: More than one thing can go wrong when the technical conditions for regression are violated.

```{r option-b1, echo=FALSE}
question("What happens if inferences is performed when the technical conditions are violated?",
  answer("If the technical conditions are violated, the software will not compute a p-value", message = "The software will always provide a p-value, even if the number is meaningless"),
  answer("If the technical conditions are violated, the p-value will not represent the probability of the data given the null hypothesis is true.", message = "True... but there is more."),
  answer("If the technical conditions are violated, the CI procedure will not capture the true parameter in 95% of samples.", message = "True... but there is more."),
  answer("All of the above.", message = "No. The p-value is always calculated, regardless of whether the distribution is appropriate."),
  answer("Some of the above.", 
       message = "Correct! When technical conditions are violated, both p-values and confidence intervals can be inaccurate. However, statistical software will still calculate these values - it's your responsibility to check the conditions first.", 
       correct = TRUE),
  allow_retry = TRUE
)
```

## Effect of Outliers on Regression

### Why Outliers Matter

A single unusual observation can dramatically affect:
* The slope and intercept of the regression line
* The p-value for testing significance
* Our confidence in the model's predictions

**Important principle:** Never remove outliers just because they don't fit your model. Only remove observations when:
1. They represent data entry errors
2. You're deliberately modeling a specific subset of your data (and you clearly report this decision)

Let's see the impact of outliers using the Starbucks nutrition data.


Just as violating technical conditions can impact the accuracy of a p-value, one or a handful of outlying values can also have an unintended impact on the regression inferential procedure.



```{r}
ggplot(starbucks, aes(x = fiber, y = protein)) + 
  geom_point() +
  stat_smooth(method = "lm", se = FALSE) + 
  geom_point(data = subset(starbucks, fiber > 15), color = "red", cex = 5) + 
  ggtitle("Fiber vs. protein")
```

Recall the linear model regressing protein on fiber.  You may have noticed previously that there was one food item with quite a bit of fiber and relatively little protein.

Additionally, maybe it turns out that you'd like to model only foods with relatively low fiber.  That is, if we remove the high fiber food, we can create a linear model which describes the relationship between fiber and protein only for foods that have less than 15g of fiber.



### Different regression lines

```{r}
ggplot(starbucks, aes(x = fiber, y = protein)) + 
  geom_point() +
  stat_smooth(method = "lm", se = FALSE) + 
  stat_smooth(data = starbucks_lowFib, method = "lm", se = FALSE, color = "red") +
  geom_point(data = subset(starbucks, fiber > 15), color = "red", cex = 5) + 
  ggtitle("Fiber vs. protein: Two regression lines")
```

Notice how the regression line changes when we remove the high-fiber outlier. The blue line uses all the data, while the red line excludes the outlier.

## Automated Diagnostic Tools

### Introduction to Diagnostic Packages

R provides several packages that automate the process of checking regression assumptions. Two popular options are:

1. **`performance`** package with `check_model()` - Modern, comprehensive diagnostics
2. **`ggfortify`** package with `autoplot()` - Traditional diagnostic plots in ggplot2 style

### Using performance::check_model()

The `check_model()` function creates a comprehensive set of diagnostic plots:

```{r ex415, exercise=TRUE, exercise.cap = "ex415"}
library(performance)
library(ggfortify)

# Fit model with non-linear data
model_nonlinear <- lm(response ~ explanatory, data = hypdata_nonlinear)

# Method 1: performance
check_model(model_nonlinear, check = c("linearity", "homogeneity", "qq"))

# Method 2: ggfortify
autoplot(model_nonlinear, which = 1:3, ncol = 3)
```

```{r question-comparison, echo=FALSE}
question("Both tools should reveal the same issue. What is the primary problem with this model?",
         answer("The residuals are not normally distributed", message = "Check the linearity plot more carefully"),
         answer("There is a non-linear relationship in the data", correct = TRUE, message = "Correct! Both tools show a clear curved pattern in the residual plots, indicating the relationship is not linear."),
         answer("The variance is not constant across fitted values", message = "While there may be some variance issues, the main problem is more fundamental"),
         answer("There are too many influential outliers", message = "The plots don't suggest problematic outliers"),
         allow_retry = TRUE
)
```

### Practice: After Transformation

See how diagnostic plots improve after applying an appropriate transformation.

```{r ex416, exercise=TRUE}
library(performance)
library(ggfortify)

# Original model (violations present)
model_before <- lm(response ~ explanatory, data = hypdata_nonlinear)

# Transformed model (should improve)
model_after <- lm(response ~ explanatory + I(explanatory^2), 
                  data = hypdata_nonlinear)

# Compare using performance
check_model(model_before, check = c("linearity", "qq"))
check_model(model_after, check = c("linearity", "qq"))

# Or compare using ggfortify
autoplot(model_before, which = 1:2, ncol = 2)
autoplot(model_after, which = 1:2, ncol = 2)
```

### Your Turn: Full Diagnostic Workflow

Practice the complete workflow with a dataset that has violations.

- Fit a linear model with `hypdata_nonnorm`
- Use `check_model()` to identify violations
- Apply an appropriate transformation
- Check diagnostics again to confirm improvement

```{r ex417, exercise=TRUE, exercise.cap = "ex417"}
library(performance)

# Step 1: Fit original model
model_original <- ___

# Step 2: Check diagnostics
___

# Step 3: Apply transformation (try sqrt or log)
model_transformed <- ___

# Step 4: Recheck diagnostics
___
```

```{r ex417-hint-1}
# Hint 1: Start with the basic model
#  Step 1: Fit original model
model_original <- lm(response ~ explanatory, data = hypdata_nonnorm)
# Step 2: Check diagnostics
check_model(model_original)
```

```{r ex417-hint-2}
# Hint 2: The data shows increasing variance and non-normality
# Try transforming the response variable
# Based on the pattern, sqrt() might work well
# #  Step 1: Fit original model
model_original <- lm(response ~ explanatory, data = hypdata_nonnorm)
# Step 2: Check diagnostics
check_model(model_original)
# Step 3: Apply transformation (try sqrt or log)
model_transformed <- lm(sqrt(response) ~ explanatory, data = hypdata_nonnorm)
```

```{r ex417-solution}
library(performance)

# Step 1: Fit original model
model_original <- lm(response ~ explanatory, data = hypdata_nonnorm)

# Step 2: Check diagnostics - shows violations!
check_model(model_original, check = c("linearity", "homogeneity", "qq"))

# Step 3: Apply transformation
model_transformed <- lm(sqrt(response) ~ explanatory, data = hypdata_nonnorm)

# Step 4: Recheck diagnostics - much better!
check_model(model_transformed, check = c("linearity", "homogeneity", "qq"))

# The transformation successfully addressed the violations
```

### Key Takeaways

```{r takeaways, echo=FALSE}
question("Which statement is TRUE about automated diagnostic tools?",
  answer("They eliminate the need to understand LINE conditions", message = "No! You still need to understand what you're looking for."),
  answer("They replace manual residual plots entirely", message = "Not quite - manual plots are still valuable for learning and custom analyses."),
  answer("They provide efficient ways to check multiple conditions simultaneously", correct = TRUE, message = "Exactly! These tools make the diagnostic process faster and more comprehensive."),
  answer("They automatically fix violations when detected", message = "These tools only identify problems - you still need to decide how to address them."),
  allow_retry = TRUE
)
```

**Remember:**

- Automated tools make diagnostics faster, not obsolete
- Always understand what each plot is testing
- No tool can tell you *how* to fix violations - that requires judgment
- When in doubt, check multiple ways (manual + automated)

###

Now you have three approaches to check regression assumptions:

1. ✓ Manual residual plots (builds understanding)
2. ✓ `performance::check_model()` (quick comprehensive check)
3. ✓ `ggfortify::autoplot()` (traditional diagnostic suite)

Use all three strategically based on your needs!

## Congratulations!

You have successfully completed this activity.
You need to generate a hash for submission, click "Next Topic", generate the hash, and submit it on Blackboard.


## Submit

```{r, echo=FALSE, context="server"}
encoder_logic()
progress_checker_logic()
```

```{r progress-check, echo=FALSE}
shiny::div(
  style = "margin-bottom: 20px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f8f9fa;",
  shiny::h4("Check Your Progress", style = "margin-top: 0;"),
  shiny::p("Click the button below to see how many required exercises you have completed."),
  shiny::actionButton("check_progress", "Check My Progress", class = "btn-primary"),
  shiny::uiOutput("progress_output")
)
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(ui_before = hash_encoder_ui)
```
